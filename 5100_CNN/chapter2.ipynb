{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "chapterId": "ByWg8Ous6HM",
    "id": "chapter_name"
   },
   "source": [
    "#  CNNを用いた画像認識の応用\n",
    "<!--\n",
    "1セッション1進出事項！  \n",
    "必須の手法をおさえて、実用レベルまで持ってく！\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "table"
   },
   "source": [
    "- **[2.1 データのかさ増し](#2.1-データのかさ増し)**\n",
    "    - **[2.1.1 ImageDataGenerator](#2.1.1-ImageDataGenerator)**\n",
    "<br><br>\n",
    "- **[2.2 正規化](#2.2-正規化)**\n",
    "    - **[2.2.1 様々な正規化手法](#2.2.1-様々な正規化手法)**\n",
    "    - **[2.2.2 標準化](#2.2.2-標準化)**\n",
    "    - **[2.2.3 白色化](#2.2.3-白色化)**\n",
    "    - **[2.2.4 バッチ正規化](#2.2.4-バッチ正規化)**\n",
    "<br><br>\n",
    "\n",
    "- **[2.3 転移学習](#2.3-転移学習)**\n",
    "    - **[2.3.1 VGG](#2.3.1-VGG)**\n",
    "    - **[2.3.2 CNNを用いた分類（cifar）](#2.3.2-)**\n",
    "<br><br>\n",
    "- **[2.5 添削問題](#2.5-添削問題)**\n",
    "\n",
    "<!--\n",
    "Early Stopping　は？と思ったけど、これはCNNより前に扱うべきか。\n",
    "ジェネレーターは、多層Pレベルではいらないし、RNN系では使わない？し、CNNでkerasで扱うのが適切かな、とか\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "SkGl8_uspBf"
   },
   "source": [
    "## 2.1 データのかさ増し"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "Sk7lIdus6rG",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 2.1.1 ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "画像認識では、画像データとそのラベル（教師データ）の組み合わせが大量に必要となります。しかしながら十分な数の画像とラベルの組み合わせを用意する事は、しばしばかなりのコストがかかります。 そこで、データの個数を十分量に増やす際に行われるテクニックとして、**画像の水増し** があります。\n",
    "\n",
    "画像の水増しといっても、ただ単にデータをコピーして量を増やすだけでは意味がありません。  \n",
    "そこで、例えば画像を **反転** したり、**ずらし** たりして新たなデータを作り出します。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_cnn/211_1.png\">\n",
    "\n",
    "ここでは、Keras の `ImageDataGenerator` を使って水増しを行っていきます。  \n",
    "\n",
    "`ImageDataGenerator` には多くの引数があり、様々な手法で簡単にデータを加工することができます。また複数の加工を組み合わせて新しい画像を生成することもできます。  \n",
    "`ImageDataGenerator` でよく使われる引数を見ていきます。\n",
    "\n",
    "```python\n",
    "datagen = ImageDataGenerator(rotation_range=0.,\n",
    "                            width_shift_range=0.,\n",
    "                            height_shift_range=0.,\n",
    "                            shear_range=0.,\n",
    "                            zoom_range=0.,\n",
    "                            channel_shift_range=0,\n",
    "                            horizontal_flip=False,\n",
    "                            vertical_flip=False)\n",
    "```\n",
    "- `rotation_range`: ランダムに回転する回転範囲（単位degree）  \n",
    "- `width_shift_range`: ランダムに水平方向に平行移動する、画像の横幅に対する割合  \n",
    "- `height_shift_range`: ランダムに垂直方向に平行移動する、画像の縦幅に対する割合  \n",
    "- `shear_range`: せん断の度合い。大きくするとより斜め方向に押しつぶされたり伸びたりしたような画像になる（単位degree）  \n",
    "- `zoom_range`: ランダムに画像を圧縮、拡大させる割合。最小で 1-zoomrange まで圧縮され、最大で 1+zoom_rangeまで拡大される。  \n",
    "- `channel_shift_range`: 入力がRGB3チャンネルの画像の場合、R,G,Bそれぞれにランダムな値を足したり引いたりする。(0~255) \n",
    "- `horizontal_flip`: `True`を指定すると、ランダムに水平方向に反転します。\n",
    "- `vertical_flip`: `True`を指定すると、ランダムに垂直方向に反転します。\n",
    "\n",
    "\n",
    "flow<br>\n",
    "`flow(x, y=None, batch_size=32, shuffle=True, seed=None, save_to_dir=None, save_prefix='', save_format='png', subset=None)`<br>\n",
    "numpyデータとラベルの配列を受け取り，拡張/正規化したデータのバッチを生成します。<br>\n",
    "\n",
    "引数<br>\n",
    "`x`: データ,4次元データである必要があります。グレースケールデータではチャネルを1にRGBデータではチャネルを3にしてください。<br>\n",
    "`y`: ラベル<br>\n",
    "`batch_size`: 整数（デフォルト: 32）<br>\n",
    "`shuffle`: 真理値（デフォルト: True）<br>\n",
    "`save_to_dir`: Noneまたは文字列（デフォルト: None）．生成された拡張画像を保存するディレクトリを指定できます（行ったことの可視化に有用です）<br>\n",
    "`save_prefix`: 文字列（デフォルト''）．画像を保存する際にファイル名に付けるプリフィックス（set_to_dirに引数が与えられた時のみ有効）<br>\n",
    "`save_format`: \"png\"または\"jpeg\"（set_to_dirに引数が与えられた時のみ有効）．デフォルトは\"png\"<br>\n",
    "\n",
    "戻り値<br>\n",
    "xが画像データのNumpy配列でyがそれに対応したラベルのNumpy配列である(x, y)から生成されるイテレータです<br>\n",
    "\n",
    "他にもいくつか引数がありいろいろな処理を行うことができるので、興味がある方は以下を参考にしてみてください。  \n",
    "\n",
    "(参考: <a href=\"https://keras.io/ja/preprocessing/image/\" target=\"_blank\">Keras公式サイト</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- `ImageDataGenerator` を用いて以下の条件の下でデータのかさ増しを行う時に使用するコードとして正しいものを選んでください。\n",
    "   - **条件**\n",
    "     - ランダムに回転する範囲は30degree\n",
    "     - ランダムに水平方向に移動する際の画像の横幅に対する割合は20%\n",
    "     - ランダムに垂直方向に反転"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "choices"
   },
   "source": [
    "- ImageDataGenerator(rotation_range=30,height_shift_range=0.2,vertical_flip=True)\n",
    "- ImageDataGenerator(rotation_range=30,height_shift_range=0.2,horizontal_flip=True)\n",
    "- ImageDataGenerator(rotation_range=30,width_shift_range=0.2,vertical_flip=True)\n",
    "- ImageDataGenerator(rotation_range=30,width_shift_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `datagen = ImageDataGenerator()` のようにしてジェネレーターを生成できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "- ImageDataGenerator(rotation_range=30,width_shift_range=0.2,vertical_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "ry4gIOOjpBf"
   },
   "source": [
    "## 2.2 正規化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "ryrlIOOjpHG",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 2.2.1 様々な正規化手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_cnn/221_1.png\">\n",
    "\n",
    "\n",
    "\n",
    "上の画像は **正規化** の例です。データにある決まりに従って処理を行い、使いやすくすることを **正規化** と言います。  \n",
    "\n",
    "上の例では **正規化** を行うことで光の当たり方を統一し、学習に直接関係のないデータ間の差異を取り除いています。これにより、学習の効率を格段に上げることができます。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_cnn/221_2.png\">\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_cnn/221_3.png\">\n",
    "\n",
    "```\n",
    "オレンジ色がBN無し、青がBN付きとなっています。\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "（出典: <a href=\"https://deepage.net/deep_learning/2016/10/26/batch_normalization.html\" target=\"_blank\">DeepAge</a>\n",
    "）\n",
    "\n",
    "上のグラフは、cifar10の分類に「バッチノーマライゼーション(BN)」という正規化を行うと正解率が大きく上がったことを示しています。\n",
    "\n",
    "<!--\n",
    "例えば顔画像認識をする際に，撮影した顔画像写真の光源の当たり方が写真によって違っていた場合，学習に悪影響をおよぼす可能性がある． \n",
    "文字認識をする際に，人によって文字の形が正方形に近かったり縦長の長方形に近かったりすることがあるが，これもアスペクト比を統一するのが望ましい． このように学習に関係ないデータ間の差異を，学習に影響を及ぼさないように取り除くことを正規化という．  \n",
    "-->\n",
    "<!--\n",
    "Mat src = imread(argv[hoge]);\n",
    "        if(src.empty()){\n",
    "            cout << \"Image not found!\" << endl;\n",
    "            return -1;\n",
    "        }\n",
    "        //特徴ベクトルの生成\n",
    "        int index;\n",
    "        float train[64];\n",
    "        for(int i=0; i<64; i++) train[i] = 0;\n",
    "        Mat norm(src.size(), src.type());\n",
    "        Mat sample(src.size(), src.type());\n",
    "        normalize(src, norm, 0, 255, NORM_MINMAX, CV_8UC3);\n",
    "        imshow(\"normalized\", norm);\n",
    "-->\n",
    "\n",
    "近年、深いニューラルネットワークモデルにおいて正規化はあまり必要ないとされることもありますが、簡単なモデルを使う際に極めて有用なことには間違いありません。\n",
    "\n",
    "深層学習に用いる正規化の方法にはいろいろあり、代表的なものを挙げると\n",
    "- バッチ正規化(BN)\n",
    "- 主成分分析（PCA）\n",
    "- 特異値分解（SVD）\n",
    "- ゼロ位相成分分析（ZCA）\n",
    "- 局所的応答正規化（LRN）\n",
    "- 大域コントラスト正規化（GCN）\n",
    "- 局所コントラスト正規化（LCN）\n",
    "\n",
    "これらの正規化手法は大きく「標準化」と「白色化」に分けられます。次のセッションからそれぞれについて見ていきます。  \n",
    "\n",
    "<!--\n",
    "GCNは、画像をまたがずに、画像内での平均と分散を求めて平均を引いて分散で割るようです。\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 正規化について述べた文として、最も適当なものを選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- 深層学習で使われる、あるいは使われていた正規化手法は全部で2種類である。\n",
    "- 正規化の処理の手順は自動的に学習される。\n",
    "- 一般的に、正規化を行うと学習効率を上げることができる。\n",
    "- 正規化の手法は、大きく「標準化」と「平均化」の二つに分けられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 正規化は、比較的単純なネットワークではモデルの精度を上げるのにとても有効な手段です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "- 一般的に、正規化を行うと学習効率を上げることができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "HyIx8O_j6SM",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 30
   },
   "source": [
    "### 2.2.2 標準化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "**標準化** は、個々の特徴を平均0、分散1にすることで、特徴ごとのデータの分布を近づける手法です。\n",
    "\n",
    "以下の画像は、cifar10のデータセットに、各特徴（ここではR,G,Bの3チャンネル）それぞれについて **標準化** を行ったものです。（見やすくなるようにさらに少し処理を入れてあります）  \n",
    "**標準化** を行うことで色合いが平均的になり灰色がかったように見えますが、逆に、それまで目立っていなかった色（R or G or B）がほかの色と同じレベルで重要視される（重みづけされる）ようになるため、隠れていた特徴を見つけやすくなります。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_cnn/222_1.png\">\n",
    "\n",
    "<!--\n",
    "標準化を式で表すと以下のようになります。\n",
    "x'_i= \\large{\\frac{x_i- \\mu}{\\sigma}}\n",
    "\\mu：元データの平均　\\sigma：元データの標準偏差\n",
    "-->\n",
    "\n",
    "<!--\n",
    "ほんとに各画像ごとに標準化してる？\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- ここからは、Keras+Tensorflowを用いた実装を行いましょう。\n",
    "- 以下の条件と右のコードに従ってcifar10のデータセットの先頭10枚の画像に標準化を行い、行わなかった時の画像と比べてください。\n",
    " - 各画像ごとに標準化を行うこと。\n",
    " - 標準化には `ImageDataGenerator` を使うこと。その際、ヒントを参考に\n",
    " `ImageDataGenerator` に適切な引数を渡すこと。\n",
    "<!--\n",
    "どっちにしようかまよったけど\n",
    "-->\n",
    "<!--\n",
    "X_batch *= 127.0 / max(abs(X_batch.min()), X_batch.max())\n",
    "X_batch += 127\n",
    "X_batch = X_batch.astype('uint8')\n",
    "-->\n",
    "<!--\n",
    "X_batch -= X_batch.min()\n",
    "X_batch *= (255.0 / X_batch.max())\n",
    "X_batch = X_batch.astype('uint8')\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i])\n",
    "plt.suptitle('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# ジェネレーターの生成\n",
    "datagen = \n",
    "\n",
    "# 標準化\n",
    "g = datagen.flow(X_train, y_train, shuffle=False)\n",
    "X_batch, y_batch = g.next()\n",
    "\n",
    "# 生成した画像を見やすくしています\n",
    "X_batch *= 127.0 / max(abs(X_batch.min()), X_batch.max())\n",
    "X_batch += 127.0\n",
    "X_batch = X_batch.astype('uint8')\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_batch[i])\n",
    "plt.suptitle('標準化結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `datagen = ImageDataGenerator()` とするとジェネレーターを生成できます。\n",
    "- 各チャンネルの平均を0に、分散を1にすることで標準化が行えます。\n",
    "- `ImageDataGenerator` に `samplewise_center=True` を指定して各画像のチャンネルごとの平均を0に、 `samplewise_std_normalization=True` を指定して各画像のチャンネルごとの分散を1にすることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i])\n",
    "plt.suptitle('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# ジェネレーターの生成\n",
    "datagen = ImageDataGenerator(samplewise_center=True, samplewise_std_normalization=True)\n",
    "\n",
    "# 標準化\n",
    "g = datagen.flow(X_train, y_train, shuffle=False)\n",
    "X_batch, y_batch = g.next()\n",
    "\n",
    "# 生成した画像を見やすくしています\n",
    "X_batch *= 127.0 / max(abs(X_batch.min()), X_batch.max())\n",
    "X_batch += 127.0\n",
    "X_batch = X_batch.astype('uint8')\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_batch[i])\n",
    "plt.suptitle('標準化結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "B1vgIOdj6rG",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 60
   },
   "source": [
    "### 2.2.3 白色化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "**白色化** はデータの成分間の相関を無くす手法です。\n",
    "\n",
    "以下の画像は、cifar10のデータセットに、各特徴（ここではR,G,Bの3チャンネル）それぞれについて **白色化** を行ったものです。（見やすくなるようにさらに少し処理を入れてあります） \n",
    "\n",
    "**白色化** を行うことで全体的に暗くなりエッジが強調されたように見えますが、これは白色化が、周りのピクセルの情報から容易に想定される色合いは無視するような効果があるからです。\n",
    "\n",
    "**白色化** によって情報量の少ない面や背景等ではなく、情報量の多いエッジ等を強調することで学習効率を上げることができます。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_cnn/223_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下の条件と右のコードに従ってcifar10のデータセットの先頭10枚の画像に白色化を行い、行わなかった時の画像と比べてください。\n",
    "- 白色化には `ImageDataGenerator` を使うこと。その際、ヒントを参考に `ImageDataGenerator` に適切な引数を渡すこと。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 今回は全データのうち、学習には300、テストには100個のデータを使用します\n",
    "X_train = X_train[:300]\n",
    "X_test = X_test[:100]\n",
    "y_train = y_train[:300]\n",
    "y_test = y_test[:100]\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i])\n",
    "plt.suptitle('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# ジェネレーターの生成\n",
    "datagen = \n",
    "\n",
    "# 白色化\n",
    "datagen.fit(X_train)\n",
    "g = datagen.flow(X_train, y_train, shuffle=False)\n",
    "X_batch, y_batch = g.next()\n",
    "\n",
    "# 生成した画像を見やすくしています\n",
    "X_batch *= 127.0 / max(abs(X_batch.min()), abs(X_batch.max()))\n",
    "X_batch += 127\n",
    "X_batch = X_batch.astype('uint8')\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_batch[i])\n",
    "plt.suptitle('白色化結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `datagen = ImageDataGenerator()` とするとジェネレーターを生成できます。\n",
    "- `ImageDataGenerator` に `zca_whitening=True` を指定することでゼロ位相成分分析を適用することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 今回は全データのうち、学習には300、テストには100個のデータを使用します\n",
    "X_train = X_train[:300]\n",
    "X_test = X_test[:100]\n",
    "y_train = y_train[:300]\n",
    "y_test = y_test[:100]\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i])\n",
    "plt.suptitle('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# ジェネレーターの生成\n",
    "datagen = ImageDataGenerator(featurewise_center=True,zca_whitening=True)\n",
    "\n",
    "# 白色化\n",
    "datagen.fit(X_train)\n",
    "g = datagen.flow(X_train, y_train, shuffle=False)\n",
    "X_batch, y_batch = g.next()\n",
    "\n",
    "# 生成した画像を見やすくしています\n",
    "X_batch *= 127.0 / max(abs(X_batch.min()), abs(X_batch.max()))\n",
    "X_batch += 127\n",
    "X_batch = X_batch.astype('uint8')\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_batch[i])\n",
    "plt.suptitle('白色化結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "SJdlUO_jarG",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 50
   },
   "source": [
    "### 2.2.4 バッチ正規化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "深層学習において、ミニバッチ学習の際にバッチごとに標準化を行うことを「 **バッチ正規化** （バッチノーマライゼーション）」と言います。\n",
    "\n",
    "Kerasでは以下のように、全結合層や畳み込み層、活性化関数などと同じようにmodelのaddメソッドでモデルに組み込むことができます。\n",
    "```python\n",
    "model.add(BatchNormalization())\n",
    "```\n",
    "**バッチ正規化** はデータの前処理としてだけではなく、中間層の出力に適用することができます。  \n",
    "特に、活性化関数ReLUなど、出力値の範囲が限定されてない関数の出力に対して **バッチ正規化** を使うと、学習がスムーズに進みやすくなり大きな効果を発揮します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 空欄にバッチノーマライゼーションを組み込む文を書き加えて実行してください。なお以下の点に注意してください。\n",
    " - 正しく正規化を使うと、活性化関数にsigmoid関数ではなくReLUを用いてもうまく学習を進めることができます。\n",
    " - ReLUを正しく使うと、sigmoid関数を使うより良い学習結果が出ることが多いです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D, BatchNormalization\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = np.reshape(a=X_train, newshape=(-1,28,28,1))[:300]\n",
    "X_test = np.reshape(a = X_test,newshape=(-1,28,28,1))[:300]\n",
    "y_train = to_categorical(y_train)[:300]\n",
    "y_test = to_categorical(y_test)[:300]\n",
    "\n",
    "# model1（活性化関数にsigmoid関数を使うモデル）の定義\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(input_shape=(28, 28, 1), filters=32,\n",
    "                 kernel_size=(2, 2), strides=(1, 1), padding=\"same\"))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Conv2D(filters=32, kernel_size=(\n",
    "    2, 2), strides=(1, 1), padding=\"same\"))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(256))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.add(Dense(128))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.add(Dense(10))\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "# コンパイル\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# 学習\n",
    "history = model1.fit(X_train, y_train, batch_size=32, epochs=3, validation_data=(X_test, y_test))\n",
    "\n",
    "# 可視化\n",
    "plt.plot(history.history['acc'], label='acc', ls='-', marker='o')\n",
    "plt.plot(history.history['val_acc'], label='val_acc', ls='-', marker='x')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.suptitle('model1', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# model2（活性化関数にReLUを使うモデル）の定義\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(input_shape=(28, 28, 1), filters=32,\n",
    "                 kernel_size=(2, 2), strides=(1, 1), padding=\"same\"))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Conv2D(filters=32, kernel_size=(\n",
    "    2, 2), strides=(1, 1), padding=\"same\"))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256))\n",
    "model2.add(Activation('relu'))\n",
    "# 以下にバッチ正規化を追加して下さい\n",
    "\n",
    "model2.add(Dense(128))\n",
    "model2.add(Activation('relu'))\n",
    "# 以下にバッチ正規化を追加して下さい\n",
    "\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "# コンパイル\n",
    "model2.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# 学習\n",
    "history = model2.fit(X_train, y_train, batch_size=32, epochs=3, validation_data=(X_test, y_test))\n",
    "\n",
    "# 可視化\n",
    "plt.plot(history.history['acc'], label='acc', ls='-', marker='o')\n",
    "plt.plot(history.history['val_acc'], label='val_acc', ls='-', marker='x')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.suptitle('model2', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- バッチ正規化は一見層ではありませんが、kerasでは他の層と同じように扱うことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D, BatchNormalization\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = np.reshape(a=X_train, newshape=(-1,28,28,1))[:300]\n",
    "X_test = np.reshape(a = X_test,newshape=(-1,28,28,1))[:300]\n",
    "y_train = to_categorical(y_train)[:300]\n",
    "y_test = to_categorical(y_test)[:300]\n",
    "\n",
    "# model1（活性化関数にsigmoid関数を使うモデル）の定義\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(input_shape=(28, 28, 1), filters=32,\n",
    "                 kernel_size=(2, 2), strides=(1, 1), padding=\"same\"))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Conv2D(filters=32, kernel_size=(\n",
    "    2, 2), strides=(1, 1), padding=\"same\"))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(256))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.add(Dense(128))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.add(Dense(10))\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# 学習\n",
    "history = model1.fit(X_train, y_train, batch_size=32, epochs=3, validation_data=(X_test, y_test))\n",
    "\n",
    "# 可視化\n",
    "plt.plot(history.history['acc'], label='acc', ls='-', marker='o')\n",
    "plt.plot(history.history['val_acc'], label='val_acc', ls='-', marker='x')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.suptitle('model1', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# model2（活性化関数にReLUを使うモデル）の定義\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(input_shape=(28, 28, 1), filters=32,\n",
    "                 kernel_size=(2, 2), strides=(1, 1), padding=\"same\"))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Conv2D(filters=32, kernel_size=(\n",
    "    2, 2), strides=(1, 1), padding=\"same\"))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256))\n",
    "model2.add(Activation('relu'))\n",
    "# 以下にバッチ正規化を追加して下さい\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(128))\n",
    "model2.add(Activation('relu'))\n",
    "# 以下にバッチ正規化を追加して下さい\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model2.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# 学習\n",
    "history = model2.fit(X_train, y_train, batch_size=32, epochs=3, validation_data=(X_test, y_test))\n",
    "\n",
    "# 可視化\n",
    "plt.plot(history.history['acc'], label='acc', ls='-', marker='o')\n",
    "plt.plot(history.history['val_acc'], label='val_acc', ls='-', marker='x')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.suptitle(\"model2\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "rytg8OuipBG"
   },
   "source": [
    "## 2.3 転移学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "HkqlI__opBM",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 2.3.1 転移学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "大規模なニューラルネットを学習させるのにはとても時間がかかり、データも大量に必要になります。  \n",
    "このような場合は、大量のデータですでに学習され公開されているモデルを用いることが有効です。学習済みのモデルを使って新たなモデルの学習を行うことを「 **転移学習** 」といいます。\n",
    "\n",
    "Kerasでは、ImageNet（120万枚，1000クラスからなる巨大な画像のデータセット）で学習した画像分類モデルとその重みをダウンロードし、使用できます。  \n",
    "公開されているモデルには何種類かありますが、ここでは **VGG16** というモデルを例に説明します。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_cnn/231_1.png\">\n",
    "\n",
    "図１VGGモデル (出典: <a href=\"https://arxiv.org/pdf/1409.1556.pdf\" target=\"_blank\">VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION</a>)\n",
    "\n",
    "<!--\n",
    "図自体は上の論文には載ってなかった。\n",
    "図のソースはわかりません...\n",
    "-->\n",
    "\n",
    "VGGモデルは、2014年のILSVRCという大規模な画像認識のコンペティションで2位になった、オックスフォード大学VGG(Visual Geometry Group)チームが作成したネットワークモデルです。（図１）\n",
    "小さいフィルターを使った畳み込みを2〜4回連続で行いさらにプーリングする、というのを繰り返し、当時としてはかなり層を深くしてあるのが特徴です。VGGモデルには、重みがある層(畳み込み層と全結合層)を16層重ねたものと19層重ねたものがあり、それぞれVGG16やVGG19と呼ばれます。VGG16は、畳み込み13層＋全結合層3層＝16層のニューラルネットワークになっています。  \n",
    "\n",
    "もともとのVGGモデルは、1000クラスの分類モデルなので出力ユニットは1000個ありますが、最後の全結合層は使わずに途中までの層を特徴抽出のための層として使うことで、転移学習に用いることができます。\n",
    "\n",
    "また、入力画像のサイズも気にする必要はありません。これは、VGG16モデルは、畳み込み層のカーネルサイズは `3x3` と小さく、また `padding='same'` とされており、極端に入力画像が小さくない限り13層を経て抽出される特徴の数が一定数確保されるためです。\n",
    "\n",
    "<!--\n",
    "Visual Geometry Groupオックスフォード大学\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 転移学習について述べた文として、最も適当なものを選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- 入力画像のサイズは、元のモデルの構造に合わせてあらかじめ拡大したり縮小したりする必要がある。\n",
    "- 元のモデルと同じ出力を想定してないモデルには、転移学習を行うことができない。\n",
    "- 転移学習では、学習済みのモデル構造を新たなモデルに使うことができるが、重みは一から学習させる必要がある。\n",
    "- 転移学習を行うと、一般的に学習に要する時間を短縮することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 元のモデルと入力や出力が異なるモデルにも転移学習を行うことができ、重みも学習済みのものを使うことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "- 転移学習を行うと、一般的に学習に要する時間を短縮することができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "B1slLOusprG",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 60
   },
   "source": [
    "### 2.3.2 VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "Kerasでcifar10のデータセットを転移学習を用いて分類します。  \n",
    "今まで使ってきた `Sequential` というタイプのモデルにVGG16のモデルを組み合わせます。\n",
    "\n",
    "まず、VGGのモデルを作ります。\n",
    "```python\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "```\n",
    "`input_tersor` として入力の形を与えます。  \n",
    "`include_top` は、もとのモデルの最後の全結合層の部分を用いるかどうかです。これを `False` にすることで元のモデルの畳み込み層による特徴抽出部分のみを用いて、それ以降の層に自分で作成したモデルを追加することができます。 `weights` は `imagenet` を指定すると、ImageNetで学習した重みを用い、`None` とするとランダムな重みを用いるようになります。\n",
    "特徴抽出部分以降に新しく他の層を追加するには、あらかじめVGGとは別のモデル（ここではtop_model）を定義し、以下のようにして結合します。\n",
    "```python\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='sigmoid'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(10, activation='softmax'))\n",
    "model = Model(inputs=vgg16.input, outputs=top_model(vgg16.output))\n",
    "```\n",
    "vgg16による特徴抽出部分の重みは更新されると崩れてしまうので以下のようにして固定します。\n",
    "```python\n",
    "# modelの20層目までがvggのモデル\n",
    "for layer in model.layers[:19]:\n",
    "    layer.trainable = False\n",
    "```\n",
    "コンパイル・学習は同様に行えますが、転移学習する場合、最適化はSGDを選択するのが良いとされています。\n",
    "```python\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- プログラムを埋めて、cifar10の分類モデルをVGG16を使って生成、転移学習させるコードを完成させてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train[:300]\n",
    "X_test = X_test[:100]\n",
    "y_train = to_categorical(y_train)[:300]\n",
    "y_test = to_categorical(y_test)[:100]\n",
    "\n",
    "#input_tensorの定義\n",
    "\n",
    "\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='sigmoid'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# vgg16とtop_modelを連結\n",
    "\n",
    "\n",
    "# 19層目までの重みを固定\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.load_weights('param_vgg.hdf5')\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=1)\n",
    "\n",
    "# 以下の式でモデルを保存することができます(ここでは行えません)\n",
    "#model.save_weights('param_vgg.hdf5')\n",
    "\n",
    "# 精度の評価\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# データの可視化（テストデータの先頭の10枚）\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_test[i])\n",
    "plt.suptitle(\"テストデータの先頭の10枚\",fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# 予測（テストデータの先頭の10枚）\n",
    "pred = np.argmax(model.predict(X_test[0:10]), axis=1)\n",
    "print(pred)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 精度は60%ほどにとどまります。訓練データをかさ増ししたり何度も学習を繰り返すと90%ほどまで出るそうですが、計算資源と時間がかなり必要になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train[:300]\n",
    "X_test = X_test[:100]\n",
    "y_train = to_categorical(y_train)[:300]\n",
    "y_test = to_categorical(y_test)[:100]\n",
    "\n",
    "#input_tensorの定義\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='sigmoid'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# vgg16とtop_modelを連結\n",
    "model = Model(inputs=vgg16.input, outputs=top_model(vgg16.output))\n",
    "\n",
    "# 19層目までの重みを固定\n",
    "for layer in model.layers[:19]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.load_weights('param_vgg.hdf5')\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=1)\n",
    "\n",
    "# 以下の式でモデルを保存することができます(ここでは行えません)\n",
    "# model.save_weights('param_vgg.hdf5')\n",
    "\n",
    "# 精度の評価\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# データの可視化（テストデータの先頭の10枚）\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_test[i])\n",
    "plt.suptitle(\"テストデータの先頭の10枚\",fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# 予測（テストデータの先頭の10枚）\n",
    "pred = np.argmax(model.predict(X_test[0:10]), axis=1)\n",
    "print(pred)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chapter_exam"
   },
   "source": [
    "## 2.5 添削問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "データのかさ増しの処理をします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下コメントアウトの処理を行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "% matplotlib inline\n",
    "\n",
    "# 画像データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#　画像の表示\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i])\n",
    "plt.suptitle('original', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 拡張する際の設定(自由に設定してください)\n",
    "generator = ImageDataGenerator(\n",
    "                    rotation_range=　　　 　　　, # 〇〇°まで回転\n",
    "                    width_shift_range=　 　　　　, # 水平方向にランダムでシフト\n",
    "                    height_shift_range=　 　　　　, # 垂直方向にランダムでシフト\n",
    "                    channel_shift_range=　 　　　　, # 色調をランダム変更\n",
    "                    shear_range=　 　　　　, # 斜め方向(pi/8まで)に引っ張る\n",
    "                    horizontal_flip=　 　　　　, # 垂直方向にランダムで反転\n",
    "                    vertical_flip=　 　　　　 # 水平方向にランダムで反転\n",
    "                    )\n",
    "\n",
    "# 画像を拡張(.flowを使って拡張する画像データを渡してください。表示した時に比較をしたいので、shuffle=Falseを指定してください)\n",
    "extension = generator.flow()\n",
    "X_batch  = extension.next()\n",
    "\n",
    "# 生成した画像を見やすくしています\n",
    "X_batch *= 127.0 / max(abs(X_batch.min()), X_batch.max())\n",
    "X_batch += 127.0\n",
    "X_batch = X_batch.astype('uint8')\n",
    "\n",
    "# 拡張した画像の表示\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_batch[i])\n",
    "plt.suptitle('extension', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- .flow(データ, 引数)で設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "% matplotlib inline\n",
    "\n",
    "# 画像データの読み込み\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#　画像の表示\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_train[i])\n",
    "plt.suptitle('original', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 拡張する際の設定(自由に設定してください)\n",
    "generator = ImageDataGenerator(\n",
    "                    rotation_range=90, # 90°まで回転\n",
    "                    width_shift_range=0.3, # 水平方向にランダムでシフト\n",
    "                    height_shift_range=0.3, # 垂直方向にランダムでシフト\n",
    "                    channel_shift_range=70.0, # 色調をランダム変更\n",
    "                    shear_range=0.39, # 斜め方向(pi/8まで)に引っ張る\n",
    "                    horizontal_flip=True, # 垂直方向にランダムで反転\n",
    "                    vertical_flip=True # 水平方向にランダムで反転\n",
    "                    )\n",
    "\n",
    "# 画像を拡張(.flowを使って拡張する画像データを渡してください。表示した時に比較をしたいので、shuffle=Falseを指定してください)\n",
    "extension = generator.flow(X_train,shuffle=False)\n",
    "X_batch = extension.next()\n",
    "\n",
    "# 生成した画像を見やすくしています\n",
    "X_batch *= 127.0 / max(abs(X_batch.min()), X_batch.max())\n",
    "X_batch += 127.0\n",
    "X_batch = X_batch.astype('uint8')\n",
    "\n",
    "# 拡張した画像の表示\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_batch[i])\n",
    "plt.suptitle('extension', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解説"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "commentary"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}