{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "chapterId": "r1UduiarG",
    "id": "chapter_name"
   },
   "source": [
    "#  CNNを用いた画像認識の基礎\n",
    "<!-- \n",
    "1セッション1進出事項！  \n",
    "とりあえずCNNできるように  \n",
    "sct  \n",
    "--> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "table"
   },
   "source": [
    "- **[1.1 深層学習画像認識](#1.1-深層学習画像認識)**\n",
    "    - **[1.1.1 画像認識](#1.1.1-画像認識)**\n",
    "<br><br>\n",
    "- **[1.2 CNN](#1.2-CNN)**\n",
    "    - **[1.2.1 CNNの概要](#1.2.1-CNNの概要)**\n",
    "    - **[1.2.2 畳み込み層](#1.2.2-畳み込み層)**\n",
    "    - **[1.2.3 プーリング層](#1.2.3-プーリング層)**\n",
    "    - **[1.2.4 CNNの実装](#1.2.4-CNNの実装)**\n",
    "    - **[1.2.5 CNNを用いた分類（MNIST）](#1.2.5-CNNを用いた分類（MNIST）)**\n",
    "    - **[1.2.6 CNNを用いた分類（cifar10）](#1.2.6-CNNを用いた分類（cifar10）)**\n",
    "<br><br>\n",
    "- **[1.3 ハイパーパラメータ](#1.3-ハイパーパラメータ)**\n",
    "    - **[1.3.1 filters （Conv層）](#1.3.1-filters-（Conv層）)**\n",
    "    - **[1.3.2 kernel_size （Conv層）](#1.3.2-kernel_size-（Conv層）)**\n",
    "    - **[1.3.3 strides （Conv層）](#1.3.3-strides-（Conv層）)**\n",
    "    - **[1.3.4 padding （Conv層）](#1.3.4-padding-（Conv層）)**\n",
    "    - **[1.3.5 pool_size （Pool層）](#1.3.5-pool_size-（Pool層）)**\n",
    "    - **[1.3.6 strides （Pool層）](#1.3.6-strides-（Pool層）)**\n",
    "    - **[1.3.7 padding （Pool層）](#1.3.7-padding-（Pool層）)**\n",
    "<br><br>\n",
    "- **[1.4 添削問題](#1.5-添削問題)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "rkxU_djpHz"
   },
   "source": [
    "## 1.1 深層学習画像認識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "Sy-I_ds6Hf",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 1.1.1 画像認識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<img src='https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_cnn/111_1.jpeg'>\n",
    "\n",
    "<center>図1.1.1-1 画像の分類、位置の検出 (出典: <a href=\"https://research.googleblog.com/2017/06/supercharge-your-computer-vision-models.html\" target=\"_blank\">[Google: Research Blog]</a>)</center>\n",
    "\n",
    "<img src='https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_cnn/111_2.gif'>\n",
    "\n",
    "<center>図1.1.1-2 画像の領域分割 (出典: <a href=\"https://blogs.nvidia.com/blog/2016/01/05/eyes-on-the-road-how-autonomous-cars-understand-what-theyre-seeing/\" target=\"_blank\">[NVIDIA: News]</a>)</center>\n",
    "\n",
    "**<font color=#AA0000>画像認識</font>** とは、画像や映像に映る文字や顔などといった **「モノ」** や **「特徴」** を検出する技術です。より具体的には、画像の分類や、モノの位置の推定（図1.1.1-1）、画像の領域分割（図1.1.1-２）など様々な認識技術が挙げられます。  \n",
    "2012年にトロント大学のチームがディープラーニングを用いた高精度の画像認識に関する研究を発表したことで、ディープラーニングに対する関心が一層高まり、現在文字認識、顔認識、自動運転、家庭用ロボットなど様々な分野で実用化が進んでいます。\n",
    "\n",
    "このコースでは、 ***CNN*** （Convolutional Neural Network、畳み込みニューラルネットワーク）と呼ばれる、画像認識に広く使われるディープニューラルネットワークを用いた深層学習手法を学んでいきます。\n",
    "\n",
    "<!-- \n",
    "画像認識の説明の参考\n",
    "MathWorks\n",
    "https://jp.mathworks.com/discovery/image-recognition.html\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 画像認識について述べた文として最も適当なものを選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- 画像認識とは、画像を分類する技術のみを指す。\n",
    "- 近年、単回帰分析を用いた画像認識手法が盛んに開発されている。\n",
    "- 画像認識はすでに完成した技術であり、求める粒度で全ての物体を認識することができる。\n",
    "- 画像認識技術は、自動運転、農業、工業など様々な分野に使われることが期待されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 画像認識の分野は現在も盛んに技術開発が行われており、年々精度が上昇しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "- 画像認識技術は、自動運転、農業、工業など様々な分野に使われることが期待されている。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "r1MI_Os6BM"
   },
   "source": [
    "## 1.2 CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "r178_uj6SG",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 1.2.1 CNNの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/CNN0.jpeg\">\n",
    "\n",
    "<center>図1.2.1-1 CNNの構造 (出典: <a href=\"http://cs231n.stanford.edu/\" target=\"_blank\">[Stanford University: Course Description]</a>)</center>\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/mylenet.png\">\n",
    "\n",
    "<center>図1.2.1-2 CNNの全体モデル (出典: <a href=\"http://deeplearning.net/tutorial/lenet.html#the-full-model-lenet\" target=\"_blank\">[theano: Convolutional Neural Networks]</a>)</center>\n",
    "\n",
    "**<font color=#AA0000>CNN</font>** （Convolutional Neural Network、畳み込みニューラルネットワーク）とは、人間の脳の視覚野と似た構造を持つ **「畳み込み層」** という層を使って特徴抽出を行うニューラルネットワークです。[ディープラーニング基礎](https://aidemy.net/courses/5090)のコースで学習した全結合層のみのニューラルネットワークと比べ、画像認識等の分野でより高い性能を発揮します。\n",
    "\n",
    "**畳み込み層** は全結合層と同じように特徴の抽出を行う層ですが、全結合層とは違い2次元のままの画像データを処理し特徴の抽出が行えるため、線や角といった  **2次元的な特徴** を抽出するのに優れています。  \n",
    "\n",
    "またCNNでは多くの場合、畳み込み層と共に **「プーリング層」** という層が使われます。 **プーリング層** で **畳み込み層** から得た情報を縮約し、最終的に画像の分類などを行います。（図1.2.1-1）\n",
    "\n",
    "次のセッションからは各層について学び、図２のようなCNNモデルを構築して実際に画像の分類を行います。\n",
    "<!-- \n",
    "webコンテンツのコース名が、深層学習入門ではなく深層学習になってるの、どうなん？\n",
    "-->\n",
    "<!-- \n",
    "deeplearning.net\n",
    "は\n",
    "theano\n",
    "作ってるところ\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- CNNについて述べた文として最も**適切でないもの**を選んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- 畳み込み層は全結合層と比べると、画素同士の位置的な関係も考慮した特徴抽出ができる点で優れている。\n",
    "- 畳み込み層で抽出する特徴量は、学習によって自動的に見つけ出される。\n",
    "- 全ての層が畳み込み層となっているニューラルネットワークモデルをCNNという。\n",
    "- CNNは、画像の分類や物体検出などによく使われるニューラルネットワークである。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- CNNには、図にも示されているように畳込み層だけでなくプーリング層や全結合層も一緒に使われることが多いです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "- 全ての層が畳み込み層となっているニューラルネットワークモデルをCNNという。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "ByNU__iTSM",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 1.2.2 畳み込み層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<img src='https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cnn.jpg'>\n",
    "\n",
    "<center>図1.2.2-1 畳み込み層とプーリング層 (出典: <a href='https://deepage.net/deep_learning/2016/11/07/convolutional_neural_network.html' target='_blank'>[DeepAge]</a>)</center>\n",
    "\n",
    " **<font color=#AA0000>畳み込み層</font>** は、図1.2.2-1のように **入力データの一部分に注目しその部分画像の特徴を調べる層** と言えます。<br>\n",
    "どのような特徴に注目すれば良いかは、学習用のデータや損失関数等を適切に定めることによって **自動的に** 学習されます。  <br>\n",
    "例えば顔認識をするCNNの場合適切に学習が進むと、 **入力層に近い畳み込み層では線や点といった低次元な概念の特徴に、出力層に近い層では目や鼻といった高次元な概念の特徴に注目するようになります** 。  （実際には、目や鼻のような高次の概念は元の入力画像から直接検出されるのではなく、入力層に近い層で検出された低次な概念の位置的な組み合わせをもとに検出されます。）  <br>\n",
    "注目すべき特徴はプログラム内部では **フィルター(カーネル)** と呼ばれる重み行列として扱われ、各特徴につき一つのフィルターを用います。\n",
    "\n",
    "<img src='https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/firstlayer.PNG'>\n",
    "\n",
    "<center>図1.2.2-2 入力層に最も近い畳み込み層の学習済みフィルターの例</center>\n",
    "\n",
    "<img src='https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/layers.png'>\n",
    "\n",
    "<center>図1.2.2-3 出力層に近い畳み込み層の学習済みフィルターの例（わかりやすく可視化されています）(出典: <a href='https://www.cs.princeton.edu/~rajeshr/papers/icml09-ConvolutionalDeepBeliefNetworks.pdf' target='_blank'>[Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations]</a>)</center>\n",
    "\n",
    "図1.2.2-3は、9x9x3（縦x横xチャンネル数）の画像に対し、3x3x3（縦x横xチャンネル数）のフィルターで畳み込みを行っている様子です。<br>\n",
    "1つの3x3x3のフィルターを使って新しく4x4x1の特徴マップ（白黒画像のようなもの）を作っています。<br>\n",
    "さらにそれぞれ異なるいくつかのフィルターを使って、全部でN枚の4x4x1のマップを作ります。<br>\n",
    "全体としてこの畳み込み層では、9x9x3の画像が、4x4xNの特徴マップに変換されます。<br>\n",
    "\n",
    "（このセッションの以下の問題も含め、畳み込み層の説明として2次元のフィルターが例として使われることが多いですが、実際には下の図のように3次元のフィルターが用いられることが多いです。）\n",
    "\n",
    "<img src='https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cntk103d_conv2d_final.gif'> \n",
    "\n",
    "<center>図1.2.2-4 畳み込みの様子 (出典: <a href='https://cntk.ai/pythondocs/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.html' target='_blank'>[Python API for CNTK]</a>)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- ここからは、畳み込み層やプーリング層で具体的にどのようなの処理が行われるのかを見ていくために、numpyで実装されたコードを使いましょう。今回は、アルゴリズムの中身を理解するため、Keras+TensorFlowなどのライブラリを使わずに実装してみます。Keras+TensorFlowによる実装例も後ほどご紹介します。\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/attachment-circle.png\">\n",
    "- このセッションでは、上の円の画像（10x10サイズのモノクロ画像）に対して以下のようなフィルターを用いて畳み込みを行い、縦、横、斜めの直線を検出します。\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/attachment-samplekernel.png\">\n",
    "- コード中のフィルター `W1` を フィルター `W2` ~ `W3` にならって適切に設定し、**縦の直線** を検出してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています\n",
    "class Conv:\n",
    "    # シンプルな例を考えるため、Wは3x3で固定し、後のセッションで扱うstridesやpaddingは考えません\n",
    "    def __init__(self, W):\n",
    "        self.W = W\n",
    "    def f_prop(self, X):\n",
    "        out = np.zeros((X.shape[0]-2, X.shape[1]-2))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                x = X[i:i+3, j:j+3]\n",
    "                # 要素ごとの積の合計をとっています\n",
    "                out[i,j] = np.dot(self.W.flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title(\"元画像\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# カーネルを適切に設定してください\n",
    "W1 = \n",
    "\n",
    "\n",
    "W2 = np.array([[0,0,0],\n",
    "               [1,1,1],\n",
    "               [0,0,0]])\n",
    "W3 = np.array([[1,0,0],\n",
    "               [0,1,0],\n",
    "               [0,0,1]])\n",
    "W4 = np.array([[0,0,1],\n",
    "               [0,1,0],\n",
    "               [1,0,0]])\n",
    "\n",
    "plt.subplot(1,4,1); plt.imshow(W1)\n",
    "plt.subplot(1,4,2); plt.imshow(W2)\n",
    "plt.subplot(1,4,3); plt.imshow(W3)\n",
    "plt.subplot(1,4,4); plt.imshow(W4)\n",
    "plt.suptitle(\"カーネル\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 畳み込み\n",
    "conv1 = Conv(W1); C1 = conv1.f_prop(X)\n",
    "conv2 = Conv(W2); C2 = conv2.f_prop(X)\n",
    "conv3 = Conv(W3); C3 = conv3.f_prop(X)\n",
    "conv4 = Conv(W4); C4 = conv4.f_prop(X)\n",
    "\n",
    "plt.subplot(1,4,1); plt.imshow(C1)\n",
    "plt.subplot(1,4,2); plt.imshow(C2)\n",
    "plt.subplot(1,4,3); plt.imshow(C3)\n",
    "plt.subplot(1,4,4); plt.imshow(C4)\n",
    "plt.suptitle(\"畳み込み結果\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 畳み込み結果の画像を見ると、特徴が検出された場所が明るくなっていることがわかります。\n",
    "- `f_prop` は、Forward Propagation （順伝播）の略です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています\n",
    "class Conv:\n",
    "    # シンプルな例を考えるため、Wは3x3で固定し、後のセッションで扱うstridesやpaddingは考えません\n",
    "    def __init__(self, W):\n",
    "        self.W = W\n",
    "    def f_prop(self, X):\n",
    "        out = np.zeros((X.shape[0]-2, X.shape[1]-2))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                x = X[i:i+3, j:j+3]\n",
    "                # 要素ごとの積の合計をとっています\n",
    "                out[i,j] = np.dot(self.W.flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title(\"元画像\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# カーネルを適切に設定してください\n",
    "W1 = np.array([[0,1,0],\n",
    "               [0,1,0],\n",
    "               [0,1,0]])\n",
    "W2 = np.array([[0,0,0],\n",
    "               [1,1,1],\n",
    "               [0,0,0]])\n",
    "W3 = np.array([[1,0,0],\n",
    "               [0,1,0],\n",
    "               [0,0,1]])\n",
    "W4 = np.array([[0,0,1],\n",
    "               [0,1,0],\n",
    "               [1,0,0]])\n",
    "\n",
    "plt.subplot(1,4,1); plt.imshow(W1)\n",
    "plt.subplot(1,4,2); plt.imshow(W2)\n",
    "plt.subplot(1,4,3); plt.imshow(W3)\n",
    "plt.subplot(1,4,4); plt.imshow(W4)\n",
    "plt.suptitle(\"カーネル\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 畳み込み\n",
    "conv1 = Conv(W1); C1 = conv1.f_prop(X)\n",
    "conv2 = Conv(W2); C2 = conv2.f_prop(X)\n",
    "conv3 = Conv(W3); C3 = conv3.f_prop(X)\n",
    "conv4 = Conv(W4); C4 = conv4.f_prop(X)\n",
    "\n",
    "plt.subplot(1,4,1); plt.imshow(C1)\n",
    "plt.subplot(1,4,2); plt.imshow(C2)\n",
    "plt.subplot(1,4,3); plt.imshow(C3)\n",
    "plt.subplot(1,4,4); plt.imshow(C4)\n",
    "plt.suptitle(\"畳み込み結果\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "ByHUuOsTSf",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 1.2.3 プーリング層"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cnn.jpg\">\n",
    "\n",
    "図1 畳み込み層とプーリング層 (出典: <a href=\"https://deepage.net/deep_learning/2016/11/07/convolutional_neural_network.html\" target=\"_blank\">[DeepAge]</a>)\n",
    "　　　　　　 　　　　　　　　　　　　　　　　　　\n",
    "\n",
    " **<font color=#AA0000>プーリング層</font>** は図1のように **畳み込み層の出力を縮約しデータの量を削減する層** と言えます。  \n",
    "図2のように、特徴マップの部分区間の最大値を取ったり（ **Maxプーリング** ）、あるいは平均を取ったり（ **Averageプーリング** ）することでデータの圧縮を実現します。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/MaxPooling.png\">\n",
    "\n",
    "図2 Maxプーリング　(出典: <a href=\"https://cntk.ai/pythondocs/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.html \" target=\"_blank\">[Python API for CNTK]</a>)\n",
    "\n",
    "「畳み込み層」セッションで扱った畳み込みを行うと、画像の中の特徴量の分布を調べることができますが、同じ特徴は同じような場所にかたまって分布していることが多く、また時に特徴が見つからない場所が広く分布していることもあるなど、畳み込み層から出力される特徴マップにはそのデータの大きさに対して無駄が多くあります。<br>  \n",
    "プーリングはそのようなデータの無駄を削減し、情報の損失を抑えながらデータを圧縮することができます。  <br>\n",
    "その反面、プーリングによって細かい位置情報は削除されてしまいますが、逆にこれは、プーリング層によって抽出された特徴が元画像の平行移動などでも影響を受けないようなロバスト性を与える役割を果たします。例えば、写真に映る手書き数字の分類を行う場合、数字の位置は重要ではありませんが、プーリングによってそのようなあまり重要でない情報を削除し、入力画像に対する被検出物の位置の変化に強いモデルを構築することができます。\n",
    "\n",
    "下の図は、5x5（縦x横）の特徴マップに対し、3x3（縦x横）のごとにプーリングを行っている様子です。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/c103d_max_pooling.gif\">\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "図3 Maxプーリング\n",
    "</div>\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/c103d_average_pooling.gif\">\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "図4 Averageプーリング\n",
    "</div>\n",
    "\n",
    "(出典: <a href=\"https://cntk.ai/pythondocs/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.html \" target=\"_blank\">[Python API for CNTK]</a>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- さて、今回もKeras+TensorFlowを用いずプーリング層を定義し、どのようにプーリングが行われるのか実装しながら理解していきましょう。\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/sampleconv.png\">\n",
    "- この特徴マップに対してMaxプーリングを行います。正しくMaxプーリングが行われると以下のような特徴マップに変換されます。（後のセッションで扱ういくつかのプーリングのパラメータは、コード中で適当に定めています）\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/samplepool.png\">\n",
    "- ヒントを参考にコード中の `Pool` クラスの空欄を適切に埋めて、正しくMaxプーリングを実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "class Conv:\n",
    "    # シンプルな例を考えるため、Wは3x3で固定し、後のセッションで扱うstridesやpaddingは考えません。\n",
    "    def __init__(self, W):\n",
    "        self.W = W\n",
    "    def f_prop(self, X):\n",
    "        out = np.zeros((X.shape[0]-2, X.shape[1]-2))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                x = X[i:i+3, j:j+3]\n",
    "                out[i,j] = np.dot(self.W.flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "# ごくシンプルなプーリング層を定義しています。\n",
    "class Pool:\n",
    "    # シンプルな例を考えるため、後のセッションで扱うstridesやpaddingは考えません。\n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "    def f_prop(self, X):\n",
    "        l = self.l\n",
    "        out = np.zeros((X.shape[0]//self.l, X.shape[1]//self.l))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                # 下の下線部を埋めて、コメントアウトをはずしてください。\n",
    "                out[i,j] = #_____(X[i*l:(i+1)*l, j*l:(j+1)*l])\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title(\"元画像\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# カーネル\n",
    "W1 = np.array([[0,1,0],\n",
    "               [0,1,0],\n",
    "               [0,1,0]])\n",
    "W2 = np.array([[0,0,0],\n",
    "               [1,1,1],\n",
    "               [0,0,0]])\n",
    "W3 = np.array([[1,0,0],\n",
    "               [0,1,0],\n",
    "               [0,0,1]])\n",
    "W4 = np.array([[0,0,1],\n",
    "               [0,1,0],\n",
    "               [1,0,0]])\n",
    "\n",
    "# 畳み込み\n",
    "conv1 = Conv(W1); C1 = conv1.f_prop(X)\n",
    "conv2 = Conv(W2); C2 = conv2.f_prop(X)\n",
    "conv3 = Conv(W3); C3 = conv3.f_prop(X)\n",
    "conv4 = Conv(W4); C4 = conv4.f_prop(X)\n",
    "\n",
    "plt.subplot(1,4,1); plt.imshow(C1)\n",
    "plt.subplot(1,4,2); plt.imshow(C2)\n",
    "plt.subplot(1,4,3); plt.imshow(C3)\n",
    "plt.subplot(1,4,4); plt.imshow(C4)\n",
    "plt.suptitle(\"畳み込み結果\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# プーリング\n",
    "pool = Pool(2)\n",
    "P1 = pool.f_prop(C1)\n",
    "P2 = pool.f_prop(C2)\n",
    "P3 = pool.f_prop(C3)\n",
    "P4 = pool.f_prop(C4)\n",
    "\n",
    "plt.subplot(1,4,1); plt.imshow(P1)\n",
    "plt.subplot(1,4,2); plt.imshow(P2)\n",
    "plt.subplot(1,4,3); plt.imshow(P3)\n",
    "plt.subplot(1,4,4); plt.imshow(P4)\n",
    "plt.suptitle(\"プーリング結果\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `X[i*l:(i+1)*l, j*l:(j+1)*l]` は、特徴マップの部分区間を表しています。\n",
    "- 行列の最大値（部分区間の最大値）は、 `np.max()` で取得できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "class Conv:\n",
    "    # シンプルな例を考えるため、Wは3x3で固定し、後のセッションで扱うstridesやpaddingは考えません。\n",
    "    def __init__(self, W):\n",
    "        self.W = W\n",
    "    def f_prop(self, X):\n",
    "        out = np.zeros((X.shape[0]-2, X.shape[1]-2))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                x = X[i:i+3, j:j+3]\n",
    "                out[i,j] = np.dot(self.W.flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "# ごくシンプルなプーリング層を定義しています。\n",
    "class Pool:\n",
    "    # シンプルな例を考えるため、後のセッションで扱うstridesやpaddingは考えません。\n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "    def f_prop(self, X):\n",
    "        l = self.l\n",
    "        out = np.zeros((X.shape[0]//self.l, X.shape[1]//self.l))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                # 下の下線部を埋めて、コメントアウトをはずしてください。\n",
    "                out[i,j] = np.max(X[i*l:(i+1)*l, j*l:(j+1)*l])\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# カーネル\n",
    "W1 = np.array([[0,1,0],\n",
    "              [0,1,0],\n",
    "              [0,1,0]])\n",
    "W2 = np.array([[0,0,0],\n",
    "              [1,1,1],\n",
    "              [0,0,0]])\n",
    "W3 = np.array([[1,0,0],\n",
    "              [0,1,0],\n",
    "              [0,0,1]])\n",
    "W4 = np.array([[0,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,0]])\n",
    "\n",
    "# 畳み込み\n",
    "conv1 = Conv(W1); C1 = conv1.f_prop(X)\n",
    "conv2 = Conv(W2); C2 = conv2.f_prop(X)\n",
    "conv3 = Conv(W3); C3 = conv3.f_prop(X)\n",
    "conv4 = Conv(W4); C4 = conv4.f_prop(X)\n",
    "\n",
    "plt.subplot(1,4,1); plt.imshow(C1)\n",
    "plt.subplot(1,4,2); plt.imshow(C2)\n",
    "plt.subplot(1,4,3); plt.imshow(C3)\n",
    "plt.subplot(1,4,4); plt.imshow(C4)\n",
    "plt.suptitle('畳み込み結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# プーリング\n",
    "pool = Pool(2)\n",
    "P1 = pool.f_prop(C1)\n",
    "P2 = pool.f_prop(C2)\n",
    "P3 = pool.f_prop(C3)\n",
    "P4 = pool.f_prop(C4)\n",
    "\n",
    "plt.subplot(1,4,1); plt.imshow(P1)\n",
    "plt.subplot(1,4,2); plt.imshow(P2)\n",
    "plt.subplot(1,4,3); plt.imshow(P3)\n",
    "plt.subplot(1,4,4); plt.imshow(P4)\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "rk8Ludj6Hz",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 30
   },
   "source": [
    "### 1.2.4 CNNの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/5090_dnn/dnn_chap1_100.gif\">\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "図 CNNの層の実装\n",
    "</div>\n",
    "\n",
    "さて、今回はKeras+TensorFlowを使ってCNNを実装しましょう。実務上では、これらのライブラリを使ってモデルを実装する場合がほとんどです。 \n",
    "Kerasでは、まずモデルを管理する **インスタンス** を作り、addメソッドで層を一層ずつ定義していきます。\n",
    "\n",
    "**インスタンス** を作ります。\n",
    "```python\n",
    "model = Sequential()\n",
    "```\n",
    "以下のようにaddメソッドを用いてモデルの層を一層ずつ追加します。   \n",
    "全結合層は以下のように定義するのでした。\n",
    "```python\n",
    "model.add(Dense(128))\n",
    "```\n",
    "**畳み込み層** は以下のようにして追加します。パラメーターは後のセッションで学びます。\n",
    "```python\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3)))\n",
    "```\n",
    "**プーリング層** は以下のようにして追加します。パラメーターは後のセッションで学びます。\n",
    "```python\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "```\n",
    "最後に **コンパイル** を行い、ニューラルネットワークモデルの生成が終了します。  \n",
    "```python\n",
    "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "```\n",
    "以下のようにすると、問題にあるようなモデル構造の表が出力されます。\n",
    "```python\n",
    "model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 下図のネットワークモデルを実装します。空欄に次の層を追加して、下図のような構造のモデルを構築し、実行してください。\n",
    "- ただし、各層のパラメータは以下に従ってください。（各パラメータの意味については後のセッションで学んでいきます。）\n",
    " - Conv2D(input_shape=(28, 28, 1), filters=32, kernel_size=(2, 2), strides=(1, 1), padding=\"same\")\n",
    " - MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\")\n",
    " - Conv2D(filters=32, kernel_size=(2, 2), strides=(1, 1), padding=\"same\")\n",
    " - MaxPooling2D(pool_size=(2, 2), strides=(1,1))\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_cnn/124q_1.png\">\n",
    "\n",
    "<!--\n",
    "import json\n",
    " \n",
    "json_string = model.to_json()\n",
    "j = json.loads(json_string)\n",
    "\n",
    "for i in range(len(j[\"config\"])): del j[\"config\"][i][\"config\"][\"name\"]\n",
    "j[\"config\"]\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ここを埋めてください\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `model.summary()` でモデルの構造を出力しています。この出力が問題の図と一致するように、モデルを定義してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(28, 28, 1), \n",
    "                 filters=32,\n",
    "                 kernel_size=(2, 2), \n",
    "                 strides=(1, 1), \n",
    "                 padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                       strides=(1,1)))\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=(2, 2), \n",
    "                 strides=(1, 1), \n",
    "                 padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                       strides=(1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "r1PU_ujaSz",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 30
   },
   "source": [
    "### 1.2.5 CNNを用いた分類（MNIST）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "**<font color=#AA0000>MNIST</font>**　とは、下図のような手書き数字のデータセットのことです。  \n",
    "各画像はサイズが28ピクセルx28ピクセルで1チャンネル（モノクロ）のデータとなっており、それぞれ0~9のクラスラベルがつけられています。\n",
    "\n",
    "CNNを使ってMNISTデータセットの分類を行っていきしょう。  \n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/mnist.png\", width=500> \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "図 MNIST(出典: <a href=\"http://corochann.com/mnist-inference-code-1202.html\" target=\"_blank\">[MNIST]</a>)\n",
    "</div>\n",
    "\n",
    "<!--\n",
    "コード参考\n",
    "keras/examples/mnist_cnn.py\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 空欄に次の層を追加して、Kerasで下図のような構造のモデルを構築し、実行してください。\n",
    "- ただし、各層のパラメータは以下に従ってください。\n",
    " - Conv2D(32, kernel_size=(3, 3), input_shape=(28,28,1))\n",
    " - Activation('relu')\n",
    " - Conv2D(filters=64, kernel_size=(3, 3))\n",
    " - Activation('relu')\n",
    " - MaxPooling2D(pool_size=(2, 2))\n",
    " - Dropout(0.25)\n",
    " - Flatten()\n",
    " - Dense(128)\n",
    " - Activation('relu')\n",
    " - Dropout(0.5)\n",
    " - Dense(10)\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_cnn/125q_1.png\">\n",
    "\n",
    "<!--\n",
    "# モデル構造の出力\n",
    "plot_model(model, \"model_mnist.png\", show_layer_names=False)\n",
    "# モデル構造の可視化\n",
    "image = plt.imread(\"model_mnist.png\")\n",
    "plt.figure(dpi=150)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データのロード\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 今回は全データのうち、学習には300、テストには100個のデータを使用します。\n",
    "# Convレイヤーは4次元配列を受け取ります。（バッチサイズx縦x横xチャンネル数）\n",
    "# MNISTのデータはRGB画像ではなくもともと3次元のデータとなっているので予め4次元に変換します。\n",
    "X_train = X_train[:300].reshape(-1, 28, 28, 1)\n",
    "X_test = X_test[:100].reshape(-1, 28, 28, 1)\n",
    "y_train = to_categorical(y_train)[:300]\n",
    "y_test = to_categorical(y_test)[:100]\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ここを埋めてください\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "# 精度の評価\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# データの可視化（テストデータの先頭の10枚）\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_test[i].reshape((28,28)), 'gray')\n",
    "plt.suptitle(\"テストデータの先頭の10枚\",fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# 予測（テストデータの先頭の10枚）\n",
    "pred = np.argmax(model.predict(X_test[0:10]), axis=1)\n",
    "print(pred)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- addメソッドを使って層を追加してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データのロード\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 今回は全データのうち、学習には300、テストには100個のデータを使用します。\n",
    "# Convレイヤーは4次元配列を受け取ります。（バッチサイズx縦x横xチャンネル数）\n",
    "# MNISTのデータはRGB画像ではなくもともと3次元のデータとなっているので予め4次元に変換します。\n",
    "X_train = X_train[:300].reshape(-1, 28, 28, 1)\n",
    "X_test = X_test[:100].reshape(-1, 28, 28, 1)\n",
    "y_train = to_categorical(y_train)[:300]\n",
    "y_test = to_categorical(y_test)[:100]\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "# 精度の評価\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# データの可視化（テストデータの先頭の10枚）\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_test[i].reshape((28,28)), 'gray')\n",
    "plt.suptitle(\"テストデータの先頭の10枚\",fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# 予測（テストデータの先頭の10枚）\n",
    "pred = np.argmax(model.predict(X_test[0:10]), axis=1)\n",
    "print(pred)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データのロード\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 今回は全データのうち、学習には300、テストには100個のデータを使用します。\n",
    "# Convレイヤーは4次元配列を受け取ります。（バッチサイズx縦x横xチャンネル数）\n",
    "# MNISTのデータはRGB画像ではなくもともと3次元のデータとなっているので予め4次元に変換します。\n",
    "X_train = X_train[:300].reshape(-1, 28, 28, 1)\n",
    "X_test = X_test[:100].reshape(-1, 28, 28, 1)\n",
    "y_train = to_categorical(y_train)[:300]\n",
    "y_test = to_categorical(y_test)[:100]\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "# 精度の評価\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# データの可視化（テストデータの先頭の10枚）\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_test[i].reshape((28,28)), 'gray')\n",
    "plt.suptitle(\"テストデータの先頭の10枚\",fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# 予測（テストデータの先頭の10枚）\n",
    "pred = np.argmax(model.predict(X_test[0:10]), axis=1)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "BJdU__iTHf",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 30
   },
   "source": [
    "### 1.2.6 CNNを用いた分類（cifar10） "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "**<font color=#AA0000>cifar10</font>** とは、下の写真のように10種類のオブジェクトが映った画像のデータセットです。\n",
    "各画像はサイズが32ピクセルx32ピクセルで3チャンネル（R,G,B）のデータとなっており、それぞれ0~9のクラスラベルがつけられています。各クラスラベルに対応するオブジェクトは以下の通りです。\n",
    "\n",
    "- 0: 飛行機\n",
    "- 1: 自動車\n",
    "- 2: 鳥\n",
    "- 3: 猫\n",
    "- 4: 鹿\n",
    "- 5: 犬\n",
    "- 6: 蛙\n",
    "- 7: 馬\n",
    "- 8: 船\n",
    "- 9: トラック\n",
    "\n",
    "CNNを使ってcifar10データセットの分類を行っていきしょう。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cifar-10.png\", width=400> \n",
    "\n",
    "(出典: <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\" target=\"_blank\">[The CIFAR-10 dataset]</a>)\n",
    "\n",
    "\n",
    "<!--\n",
    "モデル構造の参考\n",
    "GitHub keras/examples/cifar10_cnn.py\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 空欄に次の層を追加して、Kerasで下図のような構造のモデルを構築し、実行してください。\n",
    "- ただし、各層のパラメータは以下に従ってください。\n",
    " - Conv2D(64, (3, 3), padding='same')\n",
    " - Activation('relu')\n",
    " - Conv2D(64, (3, 3))\n",
    " - Activation('relu')\n",
    " - MaxPooling2D(pool_size=(2, 2))\n",
    " - Dropout(0.25)\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_cnn/126q_1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データのロード\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 今回は全データのうち、学習には300、テストには100個のデータを使用します\n",
    "X_train = X_train[:300]\n",
    "X_test = X_test[:100]\n",
    "y_train = to_categorical(y_train)[:300]\n",
    "y_test = to_categorical(y_test)[:100]\n",
    "\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# ここを埋めてください\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# コンパイル\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習に数分かかるので、あらかじめ学習させて得た重みをロードします\n",
    "model.load_weights('param_cifar10.hdf5')\n",
    "\n",
    "# 学習\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=1)\n",
    "\n",
    "# 重みの保存をする場合には以下を使います。ここでは実行できません。\n",
    "# model.save_weights('param_cifar10.hdf5')\n",
    "\n",
    "# 精度の評価\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# データの可視化（テストデータの先頭の10枚）\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_test[i])\n",
    "plt.suptitle(\"テストデータの先頭の10枚\",fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# 予測（テストデータの先頭の10枚）\n",
    "pred = np.argmax(model.predict(X_test[0:10]), axis=1)\n",
    "print(pred)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- addメソッドを使って層を追加してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "answer"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/1\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 13.9942 - acc: 0.1167\n",
      "100/100 [==============================] - 0s 2ms/step\n",
      "Test loss: 15.151009216308594\n",
      "Test accuracy: 0.06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1827230b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データのロード\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 今回は全データのうち、学習には300、テストには100個のデータを使用します\n",
    "X_train = X_train[:300]\n",
    "X_test = X_test[:100]\n",
    "y_train = to_categorical(y_train)[:300]\n",
    "y_test = to_categorical(y_test)[:100]\n",
    "\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "# コンパイル\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習に数分かかるので、あらかじめ学習させて得た重みをロードします\n",
    "#model.load_weights('./cnn_data/param_cifar10.hdf5')\n",
    "\n",
    "# 学習\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=1)\n",
    "\n",
    "# 重みの保存をする場合には以下を使います。ここでは実行できません。\n",
    "# model.save_weights('param_cifar10.hdf5')\n",
    "\n",
    "# 精度の評価\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# データの可視化（テストデータの先頭の10枚）\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_test[i])\n",
    "plt.suptitle(\"テストデータの先頭の10枚\",fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# 予測（テストデータの先頭の10枚）\n",
    "pred = np.argmax(model.predict(X_test[0:10]), axis=1)\n",
    "print(pred)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "SJtU__saBf"
   },
   "source": [
    "## 1.3 ハイパーパラメータ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "Sk5LO_s6Bz",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 1.3.1 filters （Conv層）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "畳み込み層の `filters` パラメータは、 **特徴マップの数** つまり **抽出する特徴の種類** を指定します。\n",
    "\n",
    "下の図では、1回目の畳み込み層では `filters` は20、2回目の畳み込み層でも `filters` は20となります。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cnn.jpg\">\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "図1 畳み込み層とプーリング層 (出典: <a href=\"https://deepage.net/deep_learning/2016/11/07/convolutional_neural_network.html\" target=\"_blank\">[DeepAge]</a>)\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "`filters` が小さすぎて必要な特徴が抽出できないとうまく学習を進めることができませんが、逆に大きすぎると過学習しやすくなるので注意してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 今回もアルゴリズムの中身を理解するため、Keras+TensorFlowを用いずに実装してみましょう。\n",
    "- `畳み込みの実行` の部分を正しく埋めて、`filters=10` の畳み込みを行ってください。\n",
    "- またこのとき、似た特徴マップが多く作られてしまうことを確認してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "# 1チャンネルの画像の畳み込みのみを想定しています。\n",
    "# シンプルな例を考えるため、カーネルは3x3で固定し、stridesやpaddingは考えません。\n",
    "class Conv:\n",
    "    def __init__(self, filters):\n",
    "        self.filters = filters\n",
    "        self.W = np.random.rand(filters,3,3)\n",
    "    def f_prop(self, X):\n",
    "        out = np.zeros((filters, X.shape[0]-2, X.shape[1]-2))\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i:i+3, j:j+3]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "filters=10\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv = Conv(filters=filters)\n",
    "\n",
    "# 畳み込みの実行\n",
    "C = \n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 以下はすべて可視化のためのコードです。\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,2))\n",
    "for i in range(filters):\n",
    "    plt.subplot(2,filters/2,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv.W[i])\n",
    "plt.suptitle('カーネル', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,2))\n",
    "for i in range(filters):\n",
    "    plt.subplot(2,filters/2,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C[i])\n",
    "plt.suptitle('畳み込み結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `conv.f_prop(X)` とすると `X` に畳み込みを行うことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "# 1チャンネルの画像の畳み込みのみを想定しています。\n",
    "# シンプルな例を考えるため、カーネルは3x3で固定し、stridesやpaddingは考えません。\n",
    "class Conv:\n",
    "    def __init__(self, filters):\n",
    "        self.filters = filters\n",
    "        self.W = np.random.rand(filters,3,3)\n",
    "    def f_prop(self, X):\n",
    "        out = np.zeros((filters, X.shape[0]-2, X.shape[1]-2))\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i:i+3, j:j+3]\n",
    "                    out[k, i, j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "filters=10\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv = Conv(filters=filters)\n",
    "\n",
    "# 畳み込みの実行\n",
    "C = conv.f_prop(X)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 以下はすべて可視化のためのコードです。\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,2))\n",
    "for i in range(filters):\n",
    "    plt.subplot(2,filters/2,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv.W[i])\n",
    "plt.suptitle('カーネル', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,2))\n",
    "for i in range(filters):\n",
    "    plt.subplot(2,filters/2,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C[i])\n",
    "plt.suptitle('畳み込み結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "BJiIu_sTSG",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 1.3.2 kernel_size （Conv層）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "畳み込み層の `kernel_size` パラメータは、 **カーネルのサイズ** を指定します。\n",
    "\n",
    "下の図では、1回目の畳み込み層では `kernel_size` は5x5となります。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cnn.jpg\">\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "図1 畳み込み層とプーリング層 (出典: <a href=\"https://deepage.net/deep_learning/2016/11/07/convolutional_neural_network.html\" target=\"_blank\">[DeepAge]</a>)\n",
    "</div>\n",
    "\n",
    "`kernel_size` が小さすぎると、ごく小さな特徴も検出できなくなりうまく学習を進めることができません。逆に大きすぎると、本来小さな特徴の集まりとして検出されるはずだった大きな特徴まで検出されてしまうことになり、階層構造をとらえることが得意なニューラルネットワークモデルの強みを生かせておらず非効率なモデルになってしまいます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 今回もアルゴリズムの中身を理解するため、Keras+TensorFlowを用いずに実装してみましょう。\n",
    "- `畳み込み２` の部分を正しく埋めて、`kernel_size=(6x6)` の畳み込みを行ってください。\n",
    "- またこの時、カーネルサイズが大き過ぎると何を検出したのかよくわからないぼやけた特徴マップが検出されてしまうことを確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "# 1チャンネルの画像の畳み込みのみを想定しています。\n",
    "# シンプルな例を考えるため、stridesやpaddingは考えません。\n",
    "class Conv:\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.W = np.random.rand(filters, kernel_size[0], kernel_size[1])\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.kernel_size\n",
    "        out = np.zeros((filters, X.shape[0]-k_h+1, X.shape[1]-k_w+1))\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i:i+k_h, j:j+k_w]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "# 畳み込み１\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv1 = Conv(filters=filters, kernel_size=kernel_size)\n",
    "\n",
    "# 畳み込みの実行\n",
    "C1 = conv1.f_prop(X)\n",
    "\n",
    "# 畳み込み２\n",
    "filters = 4\n",
    "kernel_size = (6,6)\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv2 = \n",
    "\n",
    "# 畳み込みの実行\n",
    "C2 = \n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 以下はすべて可視化のためのコードです。\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv1.W[i])\n",
    "plt.suptitle('カーネルの可視化', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C1[i])\n",
    "plt.suptitle('畳み込み結果1', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv2.W[i])\n",
    "plt.suptitle('カーネルの可視化', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C2[i])\n",
    "plt.suptitle('畳み込み結果2', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `畳み込み１` の実装を参考にしてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "# 1チャンネルの画像の畳み込みのみを想定しています。\n",
    "# シンプルな例を考えるため、stridesやpaddingは考えません。\n",
    "class Conv:\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.W = np.random.rand(filters, kernel_size[0], kernel_size[1])\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.kernel_size\n",
    "        out = np.zeros((filters, X.shape[0]-k_h+1, X.shape[1]-k_w+1))\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i:i+k_h, j:j+k_w]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "# 畳み込み１\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv1 = Conv(filters=filters, kernel_size=kernel_size)\n",
    "\n",
    "# 畳み込みの実行\n",
    "C1 = conv1.f_prop(X)\n",
    "\n",
    "# 畳み込み２\n",
    "filters = 4\n",
    "kernel_size = (6,6)\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv2 = Conv(filters=filters, kernel_size=kernel_size)\n",
    "\n",
    "# 畳み込みの実行\n",
    "C2 = conv2.f_prop(X)\n",
    "\n",
    "# 以下はすべて可視化のためのコードです\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv1.W[i])\n",
    "plt.suptitle('カーネルの可視化', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C1[i])\n",
    "plt.suptitle('畳み込み結果1', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv2.W[i])\n",
    "plt.suptitle('カーネルの可視化', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C2[i])\n",
    "plt.suptitle('畳み込み結果2', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "SknIudsTHG",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 1.3.3 strides （Conv層） "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "畳み込み層の `strides` パラメータは、 **特徴を抽出する間隔** 、つまり **カーネルを動かす距離** を指定します。\n",
    "\n",
    "- strides=(1,1)\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cntk103d_same_padding_no_strides.gif\", width=300> \n",
    "\n",
    "- strides=(2,2)\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cntk103d_padding_strides.gif\", width=300> \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "(出典: <a href=\"https://cntk.ai/pythondocs/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.html\" target=\"_blank\">[CNTK]</a>)\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "（オレンジ色のパネルの周りに白い枠があるのは今は気にしないでください。次のセッションで扱います。）\n",
    "\n",
    "`strides` が小さいほどきめ細かく特徴量を抽出できますが、画像中の同じ場所の同じ特徴を複数回検出してしまうなど、無駄な計算が多くなっているように思えます。  \n",
    "しかし一般的に `strides` は小さいほうが良いとされ、Kerasの `Conv2D` レイヤーでは `strides` はデフォルトで `(1,1)` となっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 今回もアルゴリズムの中身を理解するため、Keras+TensorFlowを用いずに実装してみましょう。\n",
    "- 畳み込み２ の部分を正しく埋めて、strides=(2x2) の畳み込みを行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "# 1チャンネルの画像の畳み込みのみを想定しています。\n",
    "# シンプルな例を考えるため、paddingは考えません。\n",
    "class Conv:\n",
    "    def __init__(self, filters, kernel_size, strides):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.W = np.random.rand(filters, kernel_size[0], kernel_size[1])\n",
    "    def f_prop(self, X):\n",
    "        k_h = self.kernel_size[0]\n",
    "        k_w = self.kernel_size[1]\n",
    "        s_h = self.strides[0]\n",
    "        s_w = self.strides[1]\n",
    "        out = np.zeros((filters, (X.shape[0]-k_h)//s_h+1, (X.shape[1]-k_w)//s_w+1))\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i*s_h:i*s_h+k_h, j*s_w:j*s_w+k_w]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "# 畳み込み１\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "strides = (1,1)\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv1 = Conv(filters=filters, kernel_size=kernel_size, strides=strides)\n",
    "\n",
    "# 畳み込みの実行\n",
    "C1 = conv1.f_prop(X)\n",
    "\n",
    "# 畳み込み２\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "strides = (2,2)\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv2 = \n",
    "conv2.W = conv1.W # カーネルを統一しています。\n",
    "\n",
    "# 畳み込みの実行\n",
    "C2 = \n",
    "\n",
    "# 以下はすべて可視化のためのコードです。\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv1.W[i])\n",
    "plt.suptitle('カーネルの可視化', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C1[i])\n",
    "plt.suptitle('畳み込み結果1', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv2.W[i])\n",
    "plt.suptitle('カーネルの可視化', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C2[i])\n",
    "plt.suptitle('畳み込み結果2', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 畳み込み１ の実装を参考にしてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "# 1チャンネルの画像の畳み込みのみを想定しています。\n",
    "# シンプルな例を考えるため、paddingは考えません。\n",
    "class Conv:\n",
    "    def __init__(self, filters, kernel_size, strides):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.W = np.random.rand(filters, kernel_size[0], kernel_size[1])\n",
    "    def f_prop(self, X):\n",
    "        k_h = self.kernel_size[0]\n",
    "        k_w = self.kernel_size[1]\n",
    "        s_h = self.strides[0]\n",
    "        s_w = self.strides[1]\n",
    "        out = np.zeros((filters, (X.shape[0]-k_h)//s_h+1, (X.shape[1]-k_w)//s_w+1))\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i*s_h:i*s_h+k_h, j*s_w:j*s_w+k_w]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "# 畳み込み１\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "strides = (1,1)\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv1 = Conv(filters=filters, kernel_size=kernel_size, strides=strides)\n",
    "\n",
    "# 畳み込みの実行\n",
    "C1 = conv1.f_prop(X)\n",
    "\n",
    "# 畳み込み２\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "strides = (2,2)\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv2 = Conv(filters=filters, kernel_size=kernel_size, strides=strides)\n",
    "conv2.W = conv1.W # カーネルを統一しています\n",
    "\n",
    "# 畳み込みの実行\n",
    "C2 = conv2.f_prop(X)\n",
    "\n",
    "# 以下はすべて可視化のためのコードです\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv1.W[i])\n",
    "plt.suptitle('カーネルの可視化', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C1[i])\n",
    "plt.suptitle('畳み込み結果1', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv2.W[i])\n",
    "plt.suptitle('カーネルの可視化', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C2[i])\n",
    "plt.suptitle('畳み込み結果2', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "SJ68uOoaBM",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 1.3.4 padding （Conv層）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "パディングとは、 **入力画像の周辺を0で埋めること** を指します。  \n",
    "パディングによって端のデータの特徴もよく考慮されるようになりますが、他にも、データ更新の頻度が上がることや、各層の入出力ユニット数の調整が行えることなどのメリットが考えられます。\n",
    "\n",
    "下の図のオレンジのパネルの周りの白い枠はパディングを表現していますが、これは上下に1、左右にも1パディングをした図となります。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cntk103d_same_padding_no_strides.gif\", width=300> \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "(出典: <a href=\"https://cntk.ai/pythondocs/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.html\" target=\"_blank\">[CNTK]</a>)\n",
    "</div>\n",
    "\n",
    "Keras の `Conv2D` 層では、 `padding=valid`,  `padding=same` などのようにしてパディングの仕方を指定します。  \n",
    "`padding=valid` の場合パディングは行われず、 `padding=same` の場合、出力される特徴マップが入力のサイズと一致するように、入力にパディングが行われます。  \n",
    "右のコードでは、 `padding=(1,1)` のように、パディングする幅を引数に取ります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 今回もアルゴリズムの中身を理解するため、Keras+TensorFlowを用いずに実装してみましょう。\n",
    "- 畳み込み２ の部分を正しく埋めて、padding=(2,2) の畳み込みを行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "# 1チャンネルの画像の畳み込みのみを想定しています。\n",
    "class Conv:\n",
    "    def __init__(self, filters, kernel_size, strides, padding):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.W = np.random.rand(filters, kernel_size[0], kernel_size[1])\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.kernel_size\n",
    "        s_h, s_w = self.strides\n",
    "        p_h, p_w = self.padding\n",
    "        out = np.zeros((filters, (X.shape[0]+p_h*2-k_h)//s_h+1, (X.shape[1]+p_w*2-k_w)//s_w+1))\n",
    "        # パディング\n",
    "        X = np.pad(X, ((p_h, p_h), (p_w, p_w)), 'constant', constant_values=((0,0),(0,0)))\n",
    "        self.X = X # 後でパディング結果を可視化するために保持しておきます。\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i*s_h:i*s_h+k_h, j*s_w:j*s_w+k_w]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "# 畳み込み１\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "strides = (1,1)\n",
    "padding = (0,0)\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv1 = Conv(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding)\n",
    "\n",
    "# 畳み込みの実行\n",
    "C1 = conv1.f_prop(X)\n",
    "\n",
    "# 畳み込み２\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "strides = (1,1)\n",
    "padding = (2,2)\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv2 = \n",
    "conv2.W = conv1.W # 重みを統一しています\n",
    "\n",
    "# 畳み込みの実行\n",
    "C2 = \n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 以下はすべて可視化のためのコードです。\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "plt.imshow(conv1.X)\n",
    "plt.title('畳み込み１のパディング結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv1.W[i])\n",
    "plt.suptitle('畳み込み１のカーネルの可視化', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C1[i])\n",
    "plt.suptitle('畳み込み1の結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(conv2.X)\n",
    "plt.title('畳み込み2のパディング結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv2.W[i])\n",
    "plt.suptitle('畳み込み2のカーネルの可視化', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C2[i])\n",
    "plt.suptitle('畳み込み2の結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 畳み込み１ の実装を参考にしてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "# 1チャンネルの画像の畳み込みのみを想定しています。\n",
    "class Conv:\n",
    "    def __init__(self, filters, kernel_size, strides, padding):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.W = np.random.rand(filters, kernel_size[0], kernel_size[1])\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.kernel_size\n",
    "        s_h, s_w = self.strides\n",
    "        p_h, p_w = self.padding\n",
    "        out = np.zeros((filters, (X.shape[0]+p_h*2-k_h)//s_h+1, (X.shape[1]+p_w*2-k_w)//s_w+1))\n",
    "        # パディング\n",
    "        X = np.pad(X, ((p_h, p_h), (p_w, p_w)), 'constant', constant_values=((0,0),(0,0)))\n",
    "        self.X = X # 後でパディング結果を可視化するために保持しておきます。\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i*s_h:i*s_h+k_h, j*s_w:j*s_w+k_w]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "# 畳み込み１\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "strides = (1,1)\n",
    "padding = (0,0)\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv1 = Conv(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding)\n",
    "\n",
    "# 畳み込みの実行\n",
    "C1 = conv1.f_prop(X)\n",
    "\n",
    "# 畳み込み２\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "strides = (1,1)\n",
    "padding = (2,2)\n",
    "\n",
    "# 畳み込み層の生成\n",
    "conv2 = Conv(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding)\n",
    "conv2.W = conv1.W # 重みを統一しています\n",
    "\n",
    "# 畳み込みの実行\n",
    "C2 = conv2.f_prop(X)\n",
    "\n",
    "# 以下はすべて可視化のためのコードです。\n",
    "\n",
    "plt.imshow(conv1.X)\n",
    "plt.title('畳み込み１のパディング結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv1.W[i])\n",
    "plt.suptitle('畳み込み１のカーネルの可視化', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C1[i])\n",
    "plt.suptitle('畳み込み1の結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(conv2.X)\n",
    "plt.title('畳み込み2のパディング結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(conv2.W[i])\n",
    "plt.suptitle('畳み込み2のカーネルの可視化', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C2[i])\n",
    "plt.suptitle('畳み込み2の結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "r1RIddjprM",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 1.3.5 pool_size （Pool層）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "プーリング層の `pool_size` パラメータは、 **プーリングの粗さ** を指定するパラメータです。\n",
    "\n",
    "下の図では、最初のプーリングのサイズは2x2、次のプーリングのサイズも2x2となっています。\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cnn.jpg\">\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "図1 畳み込み層とプーリング層 (出典: <a href=\"https://deepage.net/deep_learning/2016/11/07/convolutional_neural_network.html\" target=\"_blank\">[DeepAge]</a>)\n",
    "</div>\n",
    "\n",
    "`pool_size` を大きくすることで、位置に対するロバスト性が上がる（画像の中でオブジェクトが映る位置が多少変化しても出力が変化しないこと）とされますが、基本的に `pool_size` は2x2にすれば良いとされています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 今回もアルゴリズムの中身を理解するため、Keras+TensorFlowを用いずに実装してみましょう。\n",
    "- プーリング２ の部分を正しく埋めて、pool_size=(4,4) のMaxプーリングを行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "class Conv:\n",
    "    def __init__(self, W, filters, kernel_size):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.W = W # np.random.rand(filters, kernel_size[0], kernel_size[1])\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.kernel_size\n",
    "        out = np.zeros((filters, X.shape[0]-k_h+1, X.shape[1]-k_w+1))\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i:i+k_h, j:j+k_w]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "# ごくシンプルなプーリング層を定義しています。\n",
    "# 1チャンネルの特徴マップのプーリングのみを想定しています。\n",
    "class Pool:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.pool_size\n",
    "        out = np.zeros((X.shape[0]-k_h+1, X.shape[1]-k_w+1))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                out[i,j] = np.max(X[i:i+k_h, j:j+k_w])\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "local_filename_w, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/weight.npy') \n",
    "W = np.load(local_filename_w)\n",
    "\n",
    "# 畳み込み\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "conv = Conv(W=W, filters=filters, kernel_size=kernel_size)\n",
    "C = conv.f_prop(X)\n",
    "\n",
    "# プーリング１\n",
    "pool_size = (2,2)\n",
    "pool1 = Pool(pool_size)\n",
    "P1 = [pool1.f_prop(C[i]) for i in range(len(C))]\n",
    "\n",
    "# プーリング２\n",
    "pool_size = (4,4)\n",
    "pool2 = \n",
    "P2 = \n",
    "\n",
    "# 以下はすべて可視化のためのコードです。\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C[i])\n",
    "plt.suptitle('畳み込み結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(P1[i])\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(P2[i])\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- `プーリング１` の実装を参考にしてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "class Conv:\n",
    "    def __init__(self, W, filters, kernel_size):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.W = W # np.random.rand(filters, kernel_size[0], kernel_size[1])\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.kernel_size\n",
    "        out = np.zeros((filters, X.shape[0]-k_h+1, X.shape[1]-k_w+1))\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i:i+k_h, j:j+k_w]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "# ごくシンプルなプーリング層を定義しています。\n",
    "# 1チャンネルの特徴マップのプーリングのみを想定しています。\n",
    "class Pool:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.pool_size\n",
    "        out = np.zeros((X.shape[0]-k_h+1, X.shape[1]-k_w+1))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                out[i,j] = np.max(X[i:i+k_h, j:j+k_w])\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "local_filename_w, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/weight.npy') \n",
    "W = np.load(local_filename_w)\n",
    "\n",
    "# 畳み込み\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "conv = Conv(W=W, filters=filters, kernel_size=kernel_size)\n",
    "C = conv.f_prop(X)\n",
    "\n",
    "# プーリング１\n",
    "pool_size = (2,2)\n",
    "pool1 = Pool(pool_size)\n",
    "P1 = [pool1.f_prop(C[i]) for i in range(len(C))]\n",
    "\n",
    "# プーリング２\n",
    "pool_size = (4,4)\n",
    "pool2 = Pool(pool_size)\n",
    "P2 = [pool2.f_prop(C[i]) for i in range(len(C))]\n",
    "\n",
    "# 以下はすべて可視化のためのコードです。\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C[i])\n",
    "plt.suptitle('畳み込み結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(P1[i])\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(P2[i])\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "rJ1gI_OspBM",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 1.3.6 strides （Pool層）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "プーリング層の `strides` パラメータは、畳み込み層の `strides` パラメータと同様に、特徴マップをプーリングする間隔を指定します。\n",
    "\n",
    "- strides=(1,1)\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cntk103d_same_padding_no_strides.gif\", width=300> \n",
    "\n",
    "- strides=(2,2)\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cntk103d_padding_strides.gif\", width=300> \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "(出典: <a href=\"https://cntk.ai/pythondocs/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.html\" target=\"_blank\">[CNTK]</a>)\n",
    "</div>\n",
    "Kerasの `Conv2D` レイヤーでは `strides` はデフォルトで `pool_size` と一致させるようになっています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 今回もアルゴリズムの中身を理解するため、Keras+TensorFlowを用いずに実装してみましょう。\n",
    "- プーリング２ の部分を正しく埋めて、strides=(2x2) のMaxプーリングを行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "class Conv:\n",
    "    def __init__(self, W, filters, kernel_size):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.W = W # np.random.rand(filters, kernel_size[0], kernel_size[1])\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.kernel_size\n",
    "        out = np.zeros((filters, X.shape[0]-k_h+1, X.shape[1]-k_w+1))\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i:i+k_h, j:j+k_w]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "# ごくシンプルなプーリング層を定義しています。\n",
    "# 1チャンネルの特徴マップのプーリングのみを想定しています。\n",
    "class Pool:\n",
    "    def __init__(self, pool_size, strides):\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.pool_size\n",
    "        s_h, s_w = self.strides\n",
    "        out = np.zeros(((X.shape[0]-k_h)//s_h+1, (X.shape[1]-k_w)//s_w+1))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                out[i,j] = np.max(X[i*s_h:i*s_h+k_h, j*s_w:j*s_w+k_w])\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "local_filename_w, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/weight.npy') \n",
    "W = np.load(local_filename_w)\n",
    "\n",
    "# 畳み込み\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "conv = Conv(W=W, filters=filters, kernel_size=kernel_size)\n",
    "C = conv.f_prop(X)\n",
    "\n",
    "# プーリング１\n",
    "pool_size = (2,2)\n",
    "strides = (1,1)\n",
    "pool1 = Pool(pool_size, strides)\n",
    "P1 = [pool1.f_prop(C[i]) for i in range(len(C))]\n",
    "\n",
    "# プーリング２\n",
    "pool_size = (3,3)\n",
    "strides = (2,2)\n",
    "pool2 = \n",
    "P2 = \n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 以下はすべて可視化のためのコードです。\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C[i])\n",
    "plt.suptitle('畳み込み結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(P1[i])\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(P2[i])\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- プーリング１ の実装を参考にしてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "class Conv:\n",
    "    def __init__(self, W, filters, kernel_size):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.W = W # np.random.rand(filters, kernel_size[0], kernel_size[1])\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.kernel_size\n",
    "        out = np.zeros((filters, X.shape[0]-k_h+1, X.shape[1]-k_w+1))\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i:i+k_h, j:j+k_w]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "# ごくシンプルなプーリング層を定義しています。\n",
    "# 1チャンネルの特徴マップのプーリングのみを想定しています。\n",
    "class Pool:\n",
    "    def __init__(self, pool_size, strides):\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.pool_size\n",
    "        s_h, s_w = self.strides\n",
    "        out = np.zeros(((X.shape[0]-k_h)//s_h+1, (X.shape[1]-k_w)//s_w+1))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                out[i,j] = np.max(X[i*s_h:i*s_h+k_h, j*s_w:j*s_w+k_w])\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "local_filename_w, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/weight.npy') \n",
    "W = np.load(local_filename_w)\n",
    "\n",
    "# 畳み込み\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "conv = Conv(W=W, filters=filters, kernel_size=kernel_size)\n",
    "C = conv.f_prop(X)\n",
    "\n",
    "# プーリング１\n",
    "pool_size = (2,2)\n",
    "strides = (1,1)\n",
    "pool1 = Pool(pool_size, strides)\n",
    "P1 = [pool1.f_prop(C[i]) for i in range(len(C))]\n",
    "\n",
    "# プーリング２\n",
    "pool_size = (3,3)\n",
    "strides = (2,2)\n",
    "pool2 = Pool((3,3), (2,2))\n",
    "P2 = [pool2.f_prop(C[i]) for i in range(len(C))]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 以下はすべて可視化のためのコードです。\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C[i])\n",
    "plt.suptitle('畳み込み結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(P1[i])\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(P2[i])\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5100,
    "exerciseId": "Byll8__o6Hf",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 10
   },
   "source": [
    "### 1.3.7 padding （Pool層）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "畳み込み層の `padding` と同様に、プーリング層の `padding` パラメータは、パディングの仕方を指定します。\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/_9000_cntk/images/3/cntk103d_same_padding_no_strides.gif\", width=300> \n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "(出典: <a href=\"https://cntk.ai/pythondocs/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.html\" target=\"_blank\">[CNTK]</a>)\n",
    "</div>\n",
    "\n",
    "Keras の `MaxPooling2D` 層では、 `padding=valid`,  `padding=same` などのようにしてパディングの仕方を指定します。  \n",
    "`padding=valid` の場合パディングは行われず、 `padding=same` の場合、出力される特徴マップが入力のサイズと一致するように、入力にパディングが行われます。  \n",
    "右のコードでは、 `padding=(1,1)` のように、パディングする幅を引数に取ります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 今回もアルゴリズムの中身を理解するため、Keras+TensorFlowを用いずに実装してみましょう。\n",
    "- プーリング２ の部分を正しく埋めて、padding=(1x1) でMaxプーリングを行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "class Conv:\n",
    "    def __init__(self, W, filters, kernel_size):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.W = W # np.random.rand(filters, kernel_size[0], kernel_size[1])\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.kernel_size\n",
    "        out = np.zeros((filters, X.shape[0]-k_h+1, X.shape[1]-k_w+1))\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i:i+k_h, j:j+k_w]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "# ごくシンプルなプーリング層を定義しています。\n",
    "# 1チャンネルの特徴マップのプーリングのみを想定しています。\n",
    "class Pool:\n",
    "    def __init__(self, pool_size, strides, padding):\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.pool_size\n",
    "        s_h, s_w = self.strides\n",
    "        p_h, p_w = self.padding\n",
    "        out = np.zeros(((X.shape[0]+p_h*2-k_h)//s_h+1, (X.shape[1]+p_w*2-k_w)//s_w+1))\n",
    "        X = np.pad(X, ((p_h,p_h),(p_w,p_w)), 'constant', constant_values=((0,0),(0,0)))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                out[i,j] = np.max(X[i*s_h:i*s_h+k_h, j*s_w:j*s_w+k_w])\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "local_filename_w, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/weight.npy') \n",
    "W = np.load(local_filename_w)\n",
    "\n",
    "# 畳み込み\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "conv = Conv(W=W, filters=filters, kernel_size=kernel_size)\n",
    "C = conv.f_prop(X)\n",
    "\n",
    "# プーリング\n",
    "pool_size = (2,2)\n",
    "strides = (2,2)\n",
    "padding = (0,0)\n",
    "pool1 = Pool(pool_size=pool_size, strides=strides, padding=padding)\n",
    "P1 = [pool1.f_prop(C[i]) for i in range(len(C))]\n",
    "\n",
    "# プーリング\n",
    "pool_size = (2,2)\n",
    "strides = (2,2)\n",
    "padding = (1,1)\n",
    "pool2 =\n",
    "P2 = \n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 以下はすべて可視化のためのコードです。\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C[i])\n",
    "plt.suptitle('畳み込み結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(P1[i])\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(P2[i])\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- プーリング１ の実装を参考にしてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "\n",
    "# ごくシンプルな畳み込み層を定義しています。\n",
    "class Conv:\n",
    "    def __init__(self, W, filters, kernel_size):\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.W = W # np.random.rand(filters, kernel_size[0], kernel_size[1])\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.kernel_size\n",
    "        out = np.zeros((filters, X.shape[0]-k_h+1, X.shape[1]-k_w+1))\n",
    "        for k in range(self.filters):\n",
    "            for i in range(out[0].shape[0]):\n",
    "                for j in range(out[0].shape[1]):\n",
    "                    x = X[i:i+k_h, j:j+k_w]\n",
    "                    out[k,i,j] = np.dot(self.W[k].flatten(), x.flatten())\n",
    "        return out\n",
    "\n",
    "# ごくシンプルなプーリング層を定義しています。\n",
    "# 1チャンネルの特徴マップのプーリングのみを想定しています。\n",
    "class Pool:\n",
    "    def __init__(self, pool_size, strides, padding):\n",
    "        self.pool_size = pool_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "    def f_prop(self, X):\n",
    "        k_h, k_w = self.pool_size\n",
    "        s_h, s_w = self.strides\n",
    "        p_h, p_w = self.padding\n",
    "        out = np.zeros(((X.shape[0]+p_h*2-k_h)//s_h+1, (X.shape[1]+p_w*2-k_w)//s_w+1))\n",
    "        X = np.pad(X, ((p_h,p_h),(p_w,p_w)), 'constant', constant_values=((0,0),(0,0)))\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                out[i,j] = np.max(X[i*s_h:i*s_h+k_h, j*s_w:j*s_w+k_w])\n",
    "        return out\n",
    "\n",
    "local_filename, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/circle.npy') \n",
    "X = np.load(local_filename)\n",
    "\n",
    "local_filename_w, headers = urllib.request.urlretrieve('https://aidemyexcontentsdata.blob.core.windows.net/data/5100_cnn/weight.npy') \n",
    "W = np.load(local_filename_w)\n",
    "\n",
    "# 畳み込み\n",
    "filters = 4\n",
    "kernel_size = (3,3)\n",
    "conv = Conv(W=W, filters=filters, kernel_size=kernel_size)\n",
    "C = conv.f_prop(X)\n",
    "\n",
    "# プーリング\n",
    "pool_size = (2,2)\n",
    "strides = (2,2)\n",
    "padding = (0,0)\n",
    "pool1 = Pool(pool_size=pool_size, strides=strides, padding=padding)\n",
    "P1 = [pool1.f_prop(C[i]) for i in range(len(C))]\n",
    "\n",
    "# プーリング\n",
    "pool_size = (2,2)\n",
    "strides = (2,2)\n",
    "padding = (1,1)\n",
    "pool2 = Pool(pool_size=pool_size, strides=strides, padding=padding)\n",
    "P2 = [pool2.f_prop(C[i]) for i in range(len(C))]\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 以下はすべて可視化のためのコードです。\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "plt.imshow(X)\n",
    "plt.title('元画像', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(C[i])\n",
    "plt.suptitle('畳み込み結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(P1[i])\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,1))\n",
    "for i in range(filters):\n",
    "    plt.subplot(1,filters,i+1)\n",
    "    ax = plt.gca() # get current axis\n",
    "    ax.tick_params(labelbottom=\"off\", labelleft=\"off\", bottom=\"off\", left=\"off\") # 軸の削除\n",
    "    plt.imshow(P2[i])\n",
    "plt.suptitle('プーリング結果', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chapter_exam"
   },
   "source": [
    "## 1.4 添削問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "CNNの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下のコメントアウトの処理をしてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# モデルの定義\n",
    "# インスタンスを作成してください\n",
    "model = \n",
    "\n",
    "model.add(Conv2D(input_shape=(28, 28, 1), \n",
    "                 filters=32,\n",
    "                 kernel_size=(2, 2), \n",
    "                 strides=(1, 1), \n",
    "                 padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                       strides=(1,1)))\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=(2, 2), \n",
    "                 strides=(1, 1), \n",
    "                 padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                       strides=(1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "\n",
    "\n",
    "# 活性化関数はsigmoidを使ってください\n",
    "model.add()\n",
    "model.add(Dense(128))\n",
    "\n",
    "# 活性化関数はsigmoidを使ってください\n",
    "model.add()\n",
    "model.add(Dense(10))\n",
    "\n",
    "# 活性化関数はsoftmaxを使ってください\n",
    "model.add()\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- モデルのインスタンスは`Sequential()`で作成できます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# モデルの定義\n",
    "# インスタンスを作成してください\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(28, 28, 1), \n",
    "                 filters=32,\n",
    "                 kernel_size=(2, 2), \n",
    "                 strides=(1, 1), \n",
    "                 padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                       strides=(1,1)))\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=(2, 2), \n",
    "                 strides=(1, 1), \n",
    "                 padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), \n",
    "                       strides=(1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "\n",
    "# 活性化関数はsigmoidを使ってください\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(128))\n",
    "\n",
    "# 活性化関数はsigmoidを使ってください\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "\n",
    "# 活性化関数はsoftmaxを使ってください\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解説"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "commentary"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}