{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深層学習入門(ニューラルネットワーク系) - Chapter3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- **[3.1 Kerasの便利な機能](#3.1-Kerasの便利な機能)**\n",
    "    - **[3.1.1 学習過程の表示](#3.1.1-学習過程の表示)**\n",
    "    - **[3.1.2 EarlyStopping](#3.1.2-EarlyStopping)**\n",
    "    - **[3.1.3 モデル構造の出力](#3.1.3-モデル構造の出力)**\n",
    "<br><br>\n",
    "- **[3.2 精度向上](#3.2-精度向上)**\n",
    "    - **[3.2.1 最適化](#3.2.1-最適化)**\n",
    "    - **[3.2.2 ドロップアウト](#3.2.2-ドロップアウト)**\n",
    "    - **[3.2.3 ファインチューニング](#3.2.3-ファインチューニング)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Kerasの便利な機能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 学習過程の表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kerasでは学習時のモデルの精度の遷移などを記録することができます。  \n",
    "これをグラフとして表示することで、精度がどのように変化したかを視覚的に確認することができます。\n",
    "以下のようにして、学習時の履歴を変数に保存できます。\n",
    "```python\n",
    "history = model.fit(X_train, y_train, batch_size=32, epoch=5)\n",
    "```\n",
    "これで得られた履歴から、精度の変化を得るには以下のようにします。\n",
    "```python\n",
    "history.history['acc']\n",
    "```\n",
    "また、以下のように`fit()`にテストデータを渡すことでそのデータを汎化精度の計算に用います。\n",
    "```python\n",
    "history = model.fit(X_train, y_train, batch_size=32, epoch=5, validation_data=(X_test, y_test))\n",
    "```\n",
    "この、汎化精度の履歴は下のようにして得られます。\n",
    "```python\n",
    "history.history['val_acc']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のプログラムを埋めて学習時の精度(accとval_acc)の変化をプロットするプログラムを完成させてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 784)[:10000]\n",
    "X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n",
    "y_train = to_categorical(y_train)[:10000]\n",
    "y_test = to_categorical(y_test)[:1000]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# historyの取得\n",
    "\n",
    "#acc, val_accのプロット\n",
    "\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 784)[:10000]\n",
    "X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n",
    "y_train = to_categorical(y_train)[:10000]\n",
    "y_test = to_categorical(y_test)[:1000]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# historyの取得\n",
    "history = model.fit(X_train, y_train, batch_size=32,\n",
    "                    epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "#acc, val_accのプロット\n",
    "plt.plot(history.history['acc'], label='acc', ls='-', marker='o')\n",
    "plt.plot(history.history['val_acc'], label='val_acc', ls='-', marker='x')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Early Stopping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークの学習を行う際、学習が進んでいくと、減少していたテストデータに対する損失が増加し始めることがあります。  \n",
    "このような場合は、早めに学習を打ち切ったほうが汎化精度が高くなります。  \n",
    "それを行う方法がEarly Stopping(早期終了)です。\n",
    "早期終了とは、過学習を防ぐために途中で学習を打ち切ることです。<br>\n",
    "学習用・テスト用データとは別に過学習の検証用データを持っておき、学習毎に学習用データと検証用データの評価誤差を監視し、誤差が広がった場合、学習をストップする。<br>\n",
    "Kerasでは学習時のcallback関数に指定することでEarly Stoppingが行えます。\n",
    "callbackは以下のように指定します。\n",
    "```python\n",
    "from keras.callbacks import EarlyStopping\n",
    "#Early Stoppingの定義\n",
    "es = EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='min')\n",
    "#学習時のcallbacksに指定\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[es])\n",
    "```\n",
    "`monitor`は、監視する値で、`patience`は監視する値が何エポック改善しなかったら打ち切るかを指定する引数です。  \n",
    "`mode`は、モデルの改善というのが、監視する値が減少する場合か、増加する場合かを指定する引数で、`min`のとき指定する値の減少がモデルの改善を意味し、`max`のとき指定する値の増加がモデルの改善を意味します。  \n",
    "これを`auto`と指定することで、`monitor`に指定された値から自動で推定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 モデル構造の出力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kerasにはモデルの構造を画像として出力する関数が用意されています。  \n",
    "これを用いることで自分が作成したモデルの構造を視覚的に認識でき、人に伝えるときにも分かりやすくなります。\n",
    "構造の出力は以下のように行います。\n",
    "```python\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')\n",
    "```\n",
    "これにより、modelの構造がカレントディレクトリにmodel.pngとして保存されます。\n",
    "このときに、表示される名称は、各層を追加する際に下記のように、`name`で指定できます。\n",
    "```python\n",
    "model.add(Dense(10, name='output_layer'))\n",
    "```\n",
    "指定しない場合、「層の名称_番号」のようになります。 (例えば、3つ目の全結合層であればdense_3となります)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プログラムを埋めて、層の構造を出力してください。  \n",
    "ただし、層の名称は、\"dense_256\", \"dense_128\", \"dense_10\", \"softmax\"としてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=784))\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax', name=\"softmax\"))\n",
    "\n",
    "# モデル構造を保存\n",
    "\n",
    "image = plt.imread('model.png')\n",
    "plt.figure(figsize=(2, 2.8), dpi=200)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=784, name=\"dense_256\"))\n",
    "model.add(Dense(128, name=\"dense_128\"))\n",
    "model.add(Dense(10, name=\"dense_10\"))\n",
    "model.add(Activation('softmax', name=\"softmax\"))\n",
    "\n",
    "# モデル構造を保存\n",
    "plot_model(model, 'model.png')\n",
    "\n",
    "image = plt.imread('model.png')\n",
    "plt.figure(figsize=(2, 2.8), dpi=200)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 精度向上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 最適化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習率は、学習が進むにつれて変化するほうがうまく学習できる場合が多いです。  \n",
    "これを学習率の最適化といい、Adam、RMSprop、Adagradなど様々な最適化方法が提案されてきました。  \n",
    "この中で最もよく使われるのはAdamなので、最初はAdamを用いて学習し、精度が高くならない場合などに他の方法に変更すると良いです。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 ドロップアウト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットは複数のモデルを組み合わせることで、精度が向上します。<br>\n",
    "しかし、ニューラルネットワークの構造が複雑化していくにつれて、ニューロンの重みは訓練データセットに最適化されていってしまいます。``複数のモデルをそれぞれ学習させる``のには、**計算資源や時間がたくさん必要**になります。<br>\n",
    "そこで、1つのモデルのユニットの一部を学習のたびに``ランダムに除去``することで、これに似た結果を得ようとするのが**ドロップアウト**です。<br>\n",
    "これにより、ニューラルネットは特定のニューロンの存在に依存できなくなり、より``汎用的``な(学習データのみに依存しない)特徴を学習するようになります。<br>\n",
    "その結果、学習データに対する**オーバーフィッティング(過学習)**を防ぐことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 ファインチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大規模なニューラルネットを学習させるのにはとても時間がかかり、データも大量に必要になります。  \n",
    "このような場合は、大量のデータですでに学習されているモデルの一部を用いて学習させます。\n",
    "例えば、画像認識であれば、最後の全結合層のみを変更し、畳み込み部分はそのまま使います。\n",
    "Kerasでは、Xception、VGG16、VGG19、ResNet50、InceptionV3の5つの画像分類モデルをImageNetで学習した重みをダウンロードし、使用できます。\n",
    "各モデルは、入力の最低サイズがあり、[このページ](https://keras.io/ja/applications)に載っています。 \n",
    "ここではVGG16を例に説明します。\n",
    "まず、VGGのモデルを作ります。\n",
    "```python\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "input_tensor = Input(shape=(28, 28, 1))\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "```\n",
    "input_tersorとして入力の形を与えます。  \n",
    "include_topは、もとのモデルの全結合層を用いるかどうかです。これをfalseにすることで、特徴抽出部分のみを用いて、それ以降のモデルは自分で作成したモデルと結合することができます。 weightsは'imagenet'を指定すると、imagenetで学習した重みを用い、Noneとするとランダムな重みを用いるようになります。\n",
    "特徴抽出部分以降に結合するには以下のようにします。\n",
    "```python\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(10, activation='softmax'))\n",
    "#入力はvgg.input, 出力は, top_modelにvgg16の出力を入れたもの\n",
    "model = Model(inputs=vgg16.input, outputs=top_model(vgg16.output))\n",
    "```\n",
    "vgg16による特徴抽出部分の重みは更新されると崩れてしまうので以下のようにして固定します。\n",
    "```python\n",
    "# modelの15層目までがvggのモデル\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "```\n",
    "コンパイル・学習は同様に行えますが、ファインチューニングする場合、最適化はSGDで行うと良いです。\n",
    "```python\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プログラムを埋めて、cifar10をvgg16のモデルをファインチューニングし学習させてください。（精度は60%ほどにとどまります。訓練データをかさ増ししたり、何度も学習を繰り返せば90%くらい出るそうですが今回それを試す必要はありません）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "#input_tensorの定義\n",
    "#----------------------------\n",
    "\n",
    "#----------------------------\n",
    "\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='sigmoid'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# vgg16とtop_modelを連結\n",
    "#----------------------------\n",
    "\n",
    "#----------------------------\n",
    "\n",
    "# 15層目までの重みを固定\n",
    "#----------------------------\n",
    "\n",
    "\n",
    "#----------------------------\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "#input_tensorの定義\n",
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='sigmoid'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# vgg16とtop_modelを連結\n",
    "model = Model(input=vgg16.input, output=top_model(vgg16.output))\n",
    "\n",
    "# 15層目までの重みを固定\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}