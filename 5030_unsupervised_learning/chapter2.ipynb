{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "chapterId": "r1cm_CQWgbz",
    "id": "chapter_name"
   },
   "source": [
    "#  非階層的クラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "table"
   },
   "source": [
    "- **[2.1 クラスタリングの技法](#2.1-クラスタリングの技法)**\n",
    "    - **[2.1.1 階層的クラスタリング](#2.1.1-階層的クラスタリング)**\n",
    "    - **[2.1.2 非階層的クラスタリング](#2.1.2-非階層的クラスタリング)**\n",
    "<br><br>\n",
    "- **[2.2 k-means法](#2.2-k-means法)**\n",
    "    - **[2.2.1 データの集まり](#2.2.1-データの集まり)**\n",
    "    - **[2.2.2 k-means法について](#2.2.2-k-means法について)**\n",
    "    - **[2.2.3 sklearnのKMeansライブラリ](#2.2.3-sklearnのKMeansライブラリ)**\n",
    "    - **[2.2.4 SSEについて](#2.2.4-SSEについて)**\n",
    "    - **[2.2.5 エルボー法](#2.2.5-エルボー法)**\n",
    "<br><br>\n",
    "- **[2.3 DBSCAN](#2.3-DBSCAN)**\n",
    "    - **[2.3.1 DBSCANのアルゴリズム](#2.3.1-DBSCANのアルゴリズム)**\n",
    "<br><br>\n",
    "- **[2.4 添削問題](#2.4-添削問題)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "rJsmOAQWebf"
   },
   "source": [
    "## 2.1 クラスタリングの技法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5030,
    "exerciseId": "rJ5Z52IiUxf",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.1.1 階層的クラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "　**<font color=#AA0000>階層的クラスタリング</font>** とは **データの中から最も似ている組み合わせを探し出し、順番にクラスターにしていく方法であり、途中過程で階層構造になることが特徴としてあげられます。** \n",
    "　<br>具体的な例として下の図を参照してください。5つのデータ点A,B,C,D,Eがあります。この5つのデータの内最も近いもの同士をまとめて、1つのクラスターを作るということを行います。<br>\n",
    "　　　A,B,C,D,E<br>\n",
    "　　　→ **(A,B),** C,D,E<br>\n",
    " 今の場合A,Bという2つがこの中の組み合わせでは最も近い点であると計算により判断されたので、 **(A,B)** という1つのクラスターを作りました。\n",
    " \n",
    " 次に**新しく出来たクラスターも1つのデータ点とみなして、**　これを繰り返します。<br>\n",
    "　　　→ **(A,B),** **(C,D),** E<br>\n",
    "　　　→ **(A,B,C,D),** E<br>\n",
    "　　　→ **(A,B,C,D,E)**<br>\n",
    "最後に全データをまとめるクラスターまで行き着けば終了です。<br>\n",
    " データ点がどのクラスターにまとめられていったのかを表現したのが、下の右図のような **樹形図(デンドログラム)** です。\n",
    " \n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/5030_unsupervised_learning/unsupervised_chap2_10.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "以下の文章の「　」に当てはまる **言葉の組み合わせとして最も適切なもの** を以下の語群から選んでください。\n",
    "- 階層的クラスタリングにより、データから階層的な「　」が構築され、「　」が構成されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- 「クラスター」「デンドログラム」\n",
    "- 「フォレスト」「クラスタリング」\n",
    "- 「フォレスト」「デンドログラム」\n",
    "- 「クラスター」「クラスタリング」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 階層的クラスタリングは、非階層的クラスタリングと異なり、階層構造を持つことが特徴です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "- 「クラスター」「デンドログラム」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5030,
    "exerciseId": "HJsZqhLi8gM",
    "id": "quiz_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.1.2 非階層的クラスタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "**<font color=#AA0000>非階層的クラスタリング</font>** も、**階層的クラスタリングと同じくデータから似た性質のものを探し出し、クラスターを作りますが階層構造を持ちません。**\n",
    "\n",
    "データが与えられた際、**開発者があらかじめいくつのクラスターに分けるかを決定し、その数分だけデータからクラスターを作り出します。** ただ、データごとに **最適なクラスター数は決まっておりません。** 階層構造を持たないため、 **データ量が多い場合に有効な手法といえます。** \n",
    "\n",
    "**<font color=#AA0000>非階層的クラスタリング</font>** の代表的な手法である、 **k-means法** について後ほどご紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "以下の文章の「　」に当てはまる **言葉として最も適切なもの** を以下の語群から選んでください。\n",
    "- 非階層的クラスタリングは、「　　」を持たず、あらかじめ分割する「　　」を決める必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "- 「対称構造」「階層数」\n",
    "- 「階層構造」「クラスター数」\n",
    "- 「階層構造」「階層数」\n",
    "- 「対称構造」「クラスター数」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 階層的クラスタリングの難点は、事前にクラスター数を決めてあげる必要があることです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "answer"
   },
   "source": [
    "- 「階層構造」「クラスター数」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "Hy3QdR7Zxbz"
   },
   "source": [
    "## 2.2 k-means法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5030,
    "exerciseId": "Sk3Wq3LjLxz",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.2.1 データの集まり"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "　本章で、クラスタリングについて解説していく前に、 **あらかじめデータ構造を保有している練習用のデータを用意します。** この項では、クラスター数を指定した分だけデータ内でクラスターが生成される `sklearn.datasets` 内の `make_blobs` 関数についてご紹介したいと思います。\n",
    "```python\n",
    "# sklearn.datasetsのmake_blobs関数をインポート\n",
    "from sklearn.datasets import make_blobs\n",
    "# Xには1つのプロットの(x,y)が、Yにはそのプロットの所属するクラスター番号が入る\n",
    "X,Y = make_blobs(n_samples=150,   # データ点の総数\n",
    "               n_features=2,          # 特徴量（次元数）の指定  default:2 \n",
    "               centers=3,             # クラスター数\n",
    "               cluster_std=0.5,       # クラスタ内の標準偏差 \n",
    "               shuffle=True,          # サンプルをシャッフル\n",
    "               random_state=0)        # 乱数生成器の状態を指定\n",
    "```\n",
    "上記のコードにより、**Xにデータ点** 、**Yにはそのデータ点が属するクラスターのラベル** が入ります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下のコードの **クラスター数を変化させ** 、データの形状がどうなるか確認してみましょう。\n",
    "- `make_blobs()` の `centers= ` に様々な数字を入れて出力してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Xには1つのプロットの(x,y)が、Yにはそのプロットの所属するクラスター番号が入る\n",
    "X,Y = make_blobs(n_samples=150,       # サンプル点の総数\n",
    "               n_features=2,          # 特徴量（次元数）の指定  default:2 \n",
    "               centers=__,            # ここを変えてください # クラスタの個数 \n",
    "               cluster_std=0.5,       # クラスタ内の標準偏差 \n",
    "               shuffle=True,          # サンプルをシャッフル\n",
    "               random_state=0)        # 乱数生成器の状態を指定\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=\"black\", marker=\"*\", s=50)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "RESETをクリックすると元に戻ります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Xには1つのプロットの(x,y)が、Yにはそのプロットの所属するクラスター番号が入る\n",
    "X,Y = make_blobs(n_samples=150,       # サンプル点の総数\n",
    "               n_features=2,          # 特徴量（次元数）の指定  default:2 \n",
    "               centers=10,            # クラスタの個数\n",
    "               cluster_std=0.5,       # クラスタ内の標準偏差 \n",
    "               shuffle=True,          # サンプルをシャッフル\n",
    "               random_state=0)        # 乱数生成器の状態を指定\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=\"black\", marker=\"*\", s=50)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5030,
    "exerciseId": "r16Z53LiLgz",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.2.2 k-means法について"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "非階層的クラスタリングの代表的なものに、 **<font color=#AA0000>「k-means法」</font>** があります。\n",
    "\n",
    "**k-means法は、データを分散の等しいn個のクラスターに分けることができる手法です。** 各クラスターごとに **データの重心にあたる平均値$\\mu_i$** が割り当てられます。この重心のことを **「セントロイド」** と呼びます。分散の等しいクラスターに分けるには、**「SSE」** と呼ばれる指標を用います。 **SSEとは、各クラスターに含まれるデータ点とセントロイドとの差の2乗和を求めたもの(分散にあたります)であり、**  **<font color=#AA0000> k-means法</font>** はこの **SSEを全クラスターで等しくかつ最小化するようにセントロイドを選びます。**\n",
    "\n",
    "\n",
    "**<font color=#AA0000>k-means法</font>** のアルゴリズムは、3つのステップがあります。\n",
    "<br>\n",
    "\n",
    "1.はじめに、**データ群の中からk個(任意の数)のデータ点を抽出し、 そのk個の点を初期のセントロイドとします。** セントロイドの初期化の後、2つのステップを反復します。<br>\n",
    "\n",
    "2.全てのデータ点を、**最も近いセントロイドにそれぞれ割り振ります。**<br>\n",
    "\n",
    "3.次に、**各k個のセントロイドに割り振られたデータ群の重心を計算し、その重心を新たなセントロイドとして更新します。**<br> \n",
    "\n",
    "\n",
    "**ステップ3が終了する度に、前のセントロイドと新しくできたセントロイドの距離を計算します。** その距離がある程度小さくなったら、上記の反復処理を終了します。言い換えれば、セントロイドが更新してもほとんど動かなくなるまで反復を行います。\n",
    " <br><br>\n",
    "　**<font color=#AA0000>k-means法</font>** によりクラスタリングされたデータの例を以下に掲載します。\n",
    " \n",
    "<img src=\"https://aidemyexcontentspic.blob.core.windows.net/contents-pic/5030_unsupervised_learning/unsupervised_chap2_20.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下のコードを実行することにより、 **k-means法の結果** を確認して見ましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "index"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105a495c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# データセットの作成\n",
    "X,Y = make_blobs(n_samples=150, n_features=2, centers=3, cluster_std=0.5, shuffle=True, random_state=0)        \n",
    "\n",
    "# k-means法を行います。\n",
    "km = KMeans(n_clusters=3, random_state=0)\n",
    "Y_km = km.fit_predict(X) # Y_kmに各データ点が属するクラスタのラベルが入ります\n",
    "\n",
    "# グラフの描画\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,3))\n",
    "# 元データをプロット\n",
    "ax1.scatter(X[:, 0],X[:, 1],c=\"black\")\n",
    "ax1.grid()\n",
    "# クラスタリング結果をプロット\n",
    "ax2.scatter(X[Y_km==0, 0],X[Y_km==0, 1],c=\"r\",s=40,label=\"cluster 1\")\n",
    "ax2.scatter(X[Y_km==1, 0],X[Y_km==1, 1],c=\"b\",s=40,label=\"cluster 2\")\n",
    "ax2.scatter(X[Y_km==2, 0],X[Y_km==2, 1],c=\"g\",s=40,label=\"cluster 3\")\n",
    "ax2.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.60509732  1.22529553]\n",
      " [ 0.5323772   3.31338909]\n",
      " [ 0.802314    4.38196181]\n",
      " [ 0.5285368   4.49723858]\n",
      " [ 2.61858548  0.35769791]\n",
      " [ 1.59141542  4.90497725]\n",
      " [ 1.74265969  5.03846671]\n",
      " [ 2.37533328  0.08918564]\n",
      " [-2.12133364  2.66447408]\n",
      " [ 1.72039618  5.25173192]\n",
      " [ 3.1368855   1.56592763]\n",
      " [-0.37494566  2.38787435]\n",
      " [-1.84562253  2.71924635]\n",
      " [ 0.72144399  4.08475018]\n",
      " [ 0.16117091  4.53517846]\n",
      " [-1.99912714  2.71285741]\n",
      " [-1.47804153  3.2093591 ]\n",
      " [ 1.8706766   0.77797407]\n",
      " [-1.5933443   2.76898682]\n",
      " [ 2.03562611  0.31361691]\n",
      " [ 0.64003985  4.12401075]\n",
      " [ 2.4411628   1.30941574]\n",
      " [ 1.13280393  3.87673946]\n",
      " [ 1.04829186  5.03092408]\n",
      " [-1.26637157  2.62998828]\n",
      " [ 2.31690585  0.81189049]\n",
      " [ 2.36230721  1.358767  ]\n",
      " [ 1.2091013   3.53566548]\n",
      " [-2.54224625  3.95012869]\n",
      " [ 1.4815332   0.67875364]\n",
      " [-1.59487886  3.48632794]\n",
      " [-1.82556205  2.7989214 ]\n",
      " [-1.13374003  2.68467271]\n",
      " [-1.758702    3.158623  ]\n",
      " [ 0.3498724   4.69253251]\n",
      " [ 1.68548602  1.66917096]\n",
      " [ 2.989047    1.35068599]\n",
      " [ 1.73734448  1.23588031]\n",
      " [ 0.65910903  4.12241674]\n",
      " [ 1.15445328  4.65707391]\n",
      " [-1.32738084  1.53158588]\n",
      " [-1.6814105   2.07988036]\n",
      " [ 0.34102758  4.78848568]\n",
      " [ 1.87827057  0.21018801]\n",
      " [ 2.13860427  1.21517938]\n",
      " [ 2.48368283  0.57215086]\n",
      " [-1.18113464  3.26525683]\n",
      " [ 2.11114739  3.57660449]\n",
      " [-1.19371247  2.68752237]\n",
      " [ 1.45131429  4.22810872]\n",
      " [ 1.83769075  1.82229552]\n",
      " [ 0.44089377  4.83101319]\n",
      " [ 1.08040757  4.79210685]\n",
      " [ 1.84845803  0.52393625]\n",
      " [ 2.3914149   1.10139458]\n",
      " [-1.44865074  3.03397278]\n",
      " [ 0.72086751  3.71347124]\n",
      " [ 3.01673853  1.63792106]\n",
      " [-1.18199493  3.56880538]\n",
      " [ 1.34081536  4.36827878]\n",
      " [-2.31837321  3.22307195]\n",
      " [-0.54894786  3.11292892]\n",
      " [-1.6823471   2.96658234]\n",
      " [-1.53541422  3.10745813]\n",
      " [ 1.06498315  4.10289686]\n",
      " [-0.39724954  2.89675369]\n",
      " [ 1.03972612  4.50478201]\n",
      " [ 1.62465468  1.85269614]\n",
      " [-0.30022483  4.63059663]\n",
      " [ 0.12313498  5.27917503]\n",
      " [ 1.54597042  3.68637442]\n",
      " [ 1.44254976  1.31984515]\n",
      " [ 2.52889351  0.82015861]\n",
      " [ 0.38970838  5.27559792]\n",
      " [ 1.5381461   1.23846092]\n",
      " [ 0.82049381  4.33187   ]\n",
      " [ 1.56565986  4.21382491]\n",
      " [-1.93358614  2.1846701 ]\n",
      " [-1.38373217  3.22230418]\n",
      " [ 0.96217896  4.51795326]\n",
      " [ 1.71810119  0.91357894]\n",
      " [ 1.65356269  0.55288877]\n",
      " [ 0.4519936   3.59377836]\n",
      " [ 1.19820169  4.47062449]\n",
      " [ 2.20438661  1.56085661]\n",
      " [ 3.24683991  1.3699034 ]\n",
      " [ 2.51569693  1.05702749]\n",
      " [-1.79833475  3.12590728]\n",
      " [-2.0495307   3.52345491]\n",
      " [ 2.36788325  0.09663483]\n",
      " [ 2.24348029  0.34796326]\n",
      " [ 0.99914934  4.2101954 ]\n",
      " [ 1.30963873  1.11735951]\n",
      " [ 0.77468161  4.91500986]\n",
      " [ 1.70798359  0.82284639]\n",
      " [ 1.91784543  3.6299078 ]\n",
      " [-2.00487651  2.74489137]\n",
      " [-2.10499523  3.30848131]\n",
      " [ 1.39731382  0.66687136]\n",
      " [ 2.02114672  1.75433502]\n",
      " [ 1.67030948  1.16728826]\n",
      " [ 2.52997792  0.94143928]\n",
      " [-2.18016744  3.7469476 ]\n",
      " [ 2.00604126  0.56592452]\n",
      " [ 1.50307585  0.9237462 ]\n",
      " [ 1.05374379  4.49286859]\n",
      " [-1.72662853  3.10291021]\n",
      " [ 1.72330962  4.2012082 ]\n",
      " [ 0.92466065  4.50908658]\n",
      " [ 0.39369516  4.75420057]\n",
      " [-1.31377465  3.25633628]\n",
      " [ 0.78260667  4.15263595]\n",
      " [ 1.82750127  0.90640324]\n",
      " [-1.2649585   2.9620933 ]\n",
      " [ 0.98152009  5.19672257]\n",
      " [-2.49504392  3.01227156]\n",
      " [ 1.00952869  4.45502328]\n",
      " [ 1.40848818  3.93270482]\n",
      " [-1.28003312  2.85983029]\n",
      " [-1.82506103  2.89159861]\n",
      " [ 0.5408715   4.0143625 ]\n",
      " [ 2.64928242  1.05613497]\n",
      " [ 0.5226209   4.32976003]\n",
      " [ 0.16932115  4.19741719]\n",
      " [ 1.8062513   1.86242969]\n",
      " [ 1.92126584  1.29889186]\n",
      " [-1.53906708  2.54886681]\n",
      " [ 1.68289011  0.48444439]\n",
      " [-2.29730252  2.94951326]\n",
      " [-1.45592743  2.75821805]\n",
      " [-1.38694171  2.86880707]\n",
      " [-1.07181456  3.07649137]\n",
      " [ 1.40883907  1.03118909]\n",
      " [-1.58598604  2.57779316]\n",
      " [-1.58217434  3.42796862]\n",
      " [-0.77966174  1.88288975]\n",
      " [ 0.56969694  3.44064603]\n",
      " [-1.8531083   2.72240557]\n",
      " [ 1.59885641  1.4561718 ]\n",
      " [-1.84094779  2.6773687 ]\n",
      " [ 1.35678894  4.36462484]\n",
      " [ 1.1774409   3.96138228]\n",
      " [ 1.73345832 -0.21403792]\n",
      " [ 2.34356293  0.79351428]\n",
      " [-0.95073823  3.45769156]\n",
      " [-2.23893447  2.67122232]\n",
      " [-1.87292894  3.68607079]\n",
      " [-1.8897027   2.22620028]\n",
      " [ 2.25327088  0.35113291]\n",
      " [ 1.55515985  0.12527811]]\n",
      "[0 2 2 2 0 2 2 0 1 2 0 1 1 2 2 1 1 0 1 0 2 0 2 2 1 0 0 2 1 0 1 1 1 1 2 0 0\n",
      " 0 2 2 1 1 2 0 0 0 1 2 1 2 0 2 2 0 0 1 2 0 1 2 1 1 1 1 2 1 2 0 2 2 2 0 0 2\n",
      " 0 2 2 1 1 2 0 0 2 2 0 0 0 1 1 0 0 2 0 2 0 2 1 1 0 0 0 0 1 0 0 2 1 2 2 2 1\n",
      " 2 0 1 2 1 2 2 1 1 2 0 2 2 0 0 1 0 1 1 1 1 0 1 1 1 2 1 0 1 2 2 0 0 1 1 1 1\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(Y_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.60509732 2.61858548 2.37533328 3.1368855  1.8706766  2.03562611\n",
      " 2.4411628  2.31690585 2.36230721 1.4815332  1.68548602 2.989047\n",
      " 1.73734448 1.87827057 2.13860427 2.48368283 1.83769075 1.84845803\n",
      " 2.3914149  3.01673853 1.62465468 1.44254976 2.52889351 1.5381461\n",
      " 1.71810119 1.65356269 2.20438661 3.24683991 2.51569693 2.36788325\n",
      " 2.24348029 1.30963873 1.70798359 1.39731382 2.02114672 1.67030948\n",
      " 2.52997792 2.00604126 1.50307585 1.82750127 2.64928242 1.8062513\n",
      " 1.92126584 1.68289011 1.40883907 1.59885641 1.73345832 2.34356293\n",
      " 2.25327088 1.55515985]\n"
     ]
    }
   ],
   "source": [
    "print(X[Y_km==0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- コードを実行することにより、データの塊ごと色づけされていることがわかります。これは、データの塊ごとにクラスタリングされていることを示しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# データセットの作成\n",
    "X,Y = make_blobs(n_samples=150, n_features=2, centers=3, cluster_std=0.5, shuffle=True, random_state=0)        \n",
    "\n",
    "# k-means法を行います。\n",
    "km = KMeans(n_clusters=3, random_state=0)\n",
    "Y_km = km.fit_predict(X) # Y_kmに各データ点が属するクラスタのラベルが入ります\n",
    "\n",
    "# グラフの描画\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,3))\n",
    "# 元データをプロット\n",
    "ax1.scatter(X[:, 0],X[:, 1],c=\"black\")\n",
    "ax1.grid()\n",
    "# クラスタリング結果をプロット\n",
    "ax2.scatter(X[Y_km==0, 0],X[Y_km==0, 1],c=\"r\",s=40,label=\"cluster 1\")\n",
    "ax2.scatter(X[Y_km==1, 0],X[Y_km==1, 1],c=\"b\",s=40,label=\"cluster 2\")\n",
    "ax2.scatter(X[Y_km==2, 0],X[Y_km==2, 1],c=\"g\",s=40,label=\"cluster 3\")\n",
    "ax2.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5030,
    "exerciseId": "By0-52IiLeM",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.2.3 sklearnのKMeansライブラリ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "前セクションのコードで使用した通り、`sklearn.cluster`の `KMeans` クラスは、データからクラスターを探し出し、各データにクラスタ番号を割り振ります。\n",
    "\n",
    "```python\n",
    "# sklearn.clusterのKMeansクラスをインポート\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=3,       # クラスターの個数\n",
    "        nit=\"random\",　         # セントロイドの初期値をランダムに設定  default: \"k-means++\"\n",
    "          n_init=10,            # 異なるセントロイドの初期値を用いたk-meansの実行回数\n",
    "         max_iter=300,          # k-meansアルゴリズムを繰り返す最大回数\n",
    "         tol=1e-04,             # 収束と判定するための相対的な許容誤差\n",
    "         random_state=0)        # 乱数発生初期化\n",
    "    \n",
    "Y_km = km.fit_predict(X) # クラスターが存在するデータを渡し、各サンプルに対するクラスタ番号を求める\n",
    "```\n",
    "　上記のコードにより **データからクラスターを指定した分探し出し、Y_kmに各サンプルに自動的にクラスタ番号が格納されます。** `KMeans` クラスには他にも様々な関数があります。\n",
    "\n",
    "```python\n",
    "# クラスタリングの計算を実行\n",
    "km.fit(X[, y])\n",
    "# クラスタリングの計算を行い、Xを分析に用いた距離空間に変換して返す\n",
    "km.fit_transform(X[, y])\n",
    "# 計算に用いたパラメータを返す\n",
    "km.get_params([deep])\n",
    "# Xのサンプルが属しているクラスタ番号を返す\n",
    "km.predict(X)\n",
    "# パラメータを設定する\n",
    "km.set_params(**params)\n",
    "# Xを分析に用いた距離空間に変換して返す\n",
    "km.transform(X[, y])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下のコードを実行して、`KMeans` クラスが **どのようにデータのクラスタリングを行うか** をみてみましょう。\n",
    "- 適宜、`KMeans` クラスのクラスター数のパラメータを変更させ、クラスタリングが適切な場合と不適切な場合を確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# サンプルデータの生成\n",
    "X,Y = make_blobs(n_samples=150, n_features=2, centers=3, cluster_std=0.5, shuffle=True, random_state=0)        \n",
    "\n",
    "# KMeansクラスからkmインスタンスを作成\n",
    "km = KMeans(n_clusters=3,            # クラスターの個数 # 変更してみてください\n",
    "            init=\"random\",           # セントロイドの初期値をランダムに設定  default: \"k-means++\"\n",
    "            n_init=10,               # 異なるセントロイドの初期値を用いたk-meansの実行回数\n",
    "            max_iter=300,            # k-meansアルゴリズムを繰り返す最大回数\n",
    "            tol=1e-04,               # 収束と判定するための相対的な許容誤差\n",
    "            random_state=0)          # 乱数発生初期化\n",
    "\n",
    "# fit_predictメソッドによりクラスタリングを行う\n",
    "Y_km = km.fit_predict(X)\n",
    "\n",
    "\n",
    "# クラスター番号(Y_km)に応じてデータをプロット\n",
    "for n in range(np.max(Y_km)+1):\n",
    "    plt.scatter(X[Y_km==n,0], X[Y_km==n,1], s=50, c = cm.hsv(float(n) / 10), marker=\"*\", label=\"cluster\"+str(n+1))\n",
    "    \n",
    "# セントロイドをプロット、km.cluster_centers_には各クラスターのセントロイドの座標が入っています\n",
    "plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:,1], s=250, marker=\"*\", c=\"black\", label=\"centroids\")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.7),loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- make_blobs関数にて設定したクラスター数と、KMeansクラスのパラメータとして設定したクラスター数を一致させると、クラスタリングが適切に行われます。異なっていると、正しいクラスタリングができないケースが多いです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# サンプルデータの生成\n",
    "X,Y = make_blobs(n_samples=150, n_features=2, centers=3, cluster_std=0.5, shuffle=True, random_state=0)        \n",
    "\n",
    "# KMeansクラスからkmインスタンスを作成\n",
    "km = KMeans(n_clusters=3,            # クラスターの個数 # 変更してみてください\n",
    "            init=\"random\",           # セントロイドの初期値をランダムに設定  default: \"k-means++\"\n",
    "            n_init=10,               # 異なるセントロイドの初期値を用いたk-meansの実行回数\n",
    "            max_iter=300,            # k-meansアルゴリズムを繰り返す最大回数\n",
    "            tol=1e-04,               # 収束と判定するための相対的な許容誤差\n",
    "            random_state=0)          # 乱数発生初期化\n",
    "\n",
    "# fit_predictメソッドによりクラスタリングを行う\n",
    "Y_km = km.fit_predict(X)\n",
    "\n",
    "\n",
    "# クラスター番号(Y_km)に応じてデータをプロット\n",
    "for n in range(np.max(Y_km)+1):\n",
    "    plt.scatter(X[Y_km==n,0], X[Y_km==n,1], s=50, c = cm.hsv(float(n) / 10), marker=\"*\", label=\"cluster\"+str(n+1))\n",
    "    \n",
    "# セントロイドをプロット、km.cluster_centers_には各クラスターのセントロイドの座標が入っています\n",
    "plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:,1], s=250, marker=\"*\", c=\"black\", label=\"centroids\")\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.7),loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5030,
    "exerciseId": "Bkkz5nLsIlf",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.2.4 SSEについて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "　クラスタリングの性能評価関数の一つに **「SSE」(クラスタ内誤差平方和)** があります**SSEを用いることにより様々なk-meansクラスタリングの性能を評価** することができます。 SSEの数式は省略しますが、**SSEの値はクラスタ内の値がどれだけ離れているのかを示します**。\n",
    " \n",
    "　sklearnでは `KMeans` クラスの`inertia_` 属性を通じて **SSEの値を取得できます** 。各データが **自身の属するクラスター重心からどれほどずれているか(分散)の総和** が **SSE** であるため、**SSEの値が小さいほどクラスタリングがうまくいっているモデル** と言えます。\n",
    " \n",
    "```python\n",
    "# クラスタ内誤差平方和にアクセスする\n",
    "print (\"Distortion: %.2f\"% km.inertia_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 以下のコードを実行することにより、**SSEの値を確認** してみましょう。また `KMeans` のクラスター数を変更すると **SSEの値がどのように変化するか** 確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# サンプルデータの生成\n",
    "X,Y = make_blobs(n_samples=150, n_features=2, centers=3, cluster_std=0.5, shuffle=True, random_state=0)     \n",
    "\n",
    "# KMeansクラスからkmインスタンスを作成\n",
    "km = KMeans(n_clusters=3,            # クラスターの個数 # 変更してみてください\n",
    "            init=\"random\",           # セントロイドの初期値をランダムに設定  default: \"k-means++\"\n",
    "            n_init=1,               # 異なるセントロイドの初期値を用いたk-meansの実行回数\n",
    "            max_iter=300,            # k-meansアルゴリズムを繰り返す最大回数\n",
    "            tol=1e-04,               # 収束と判定するための相対的な許容誤差\n",
    "            random_state=0)          # 乱数発生初期化\n",
    "\n",
    "# fit_predictメソッドによりクラスタリングを行う\n",
    "Y_km = km.fit_predict(X)\n",
    "\n",
    "# SSE値を出力\n",
    "print(\"Distortion: %.2f\"% km.inertia_)\n",
    "\n",
    "# プロット\n",
    "for n in range(np.max(Y_km)+1):\n",
    "    plt.scatter(X[Y_km==n,0], X[Y_km==n,1], s=50, c = cm.hsv(float(n) / 10), marker=\"*\", label=\"cluster\"+str(n+1))\n",
    "plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:,1], s=250, marker=\"*\", c=\"black\", label=\"centroids\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.7),loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 基本的にSSEの値が小さい程、クラスタリングがうまくいっていると言えますが、SSEの定義の関係から基本的にクラスター数が増えるほど値が小さくなっていきます。真に良いクラスター数の判断は、次のエルボー法によって行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# サンプルデータの生成\n",
    "X,Y = make_blobs(n_samples=150, n_features=2, centers=3, cluster_std=0.5, shuffle=True, random_state=0)     \n",
    "\n",
    "# KMeansクラスからkmインスタンスを作成\n",
    "km = KMeans(n_clusters=3,            # クラスターの個数 # 変更してみてください\n",
    "            init=\"random\",           # セントロイドの初期値をランダムに設定  default: \"k-means++\"\n",
    "            n_init=1,               # 異なるセントロイドの初期値を用いたk-meansの実行回数\n",
    "            max_iter=300,            # k-meansアルゴリズムを繰り返す最大回数\n",
    "            tol=1e-04,               # 収束と判定するための相対的な許容誤差\n",
    "            random_state=0)          # 乱数発生初期化\n",
    "\n",
    "# fit_predictメソッドによりクラスタリングを行う\n",
    "Y_km = km.fit_predict(X)\n",
    "\n",
    "# SSE値を出力\n",
    "print(\"Distortion: %.2f\"% km.inertia_)\n",
    "\n",
    "# プロット\n",
    "for n in range(np.max(Y_km)+1):\n",
    "    plt.scatter(X[Y_km==n,0], X[Y_km==n,1], s=50, c = cm.hsv(float(n) / 10), marker=\"*\", label=\"cluster\"+str(n+1))\n",
    "plt.scatter(km.cluster_centers_[:,0], km.cluster_centers_[:,1], s=250, marker=\"*\", c=\"black\", label=\"centroids\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 0.7),loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5030,
    "exerciseId": "r1lz5hUo8ef",
    "id": "code_session_name",
    "important": false,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.2.5 エルボー法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "**k-meansクラスタリングで指定するクラスター数はどう決めれば良いか** といった問題があります。\n",
    "\n",
    "このクラスター数を決定する時に参考になる手法があります。これは、 **<font color=#AA0000>エルボー法</font>** と呼ばれ、 **クラスタ数を大きくしていった時にSSEがどのように変化するか** プロットし、その結果から **k-meansのクラスタ数を決定する** 手法です。問題にあるコードを実行すればわかりますが、 **SSEの値がガクンと曲がる点があります。この時のクラスター数が最適なものとみなすことができます。** プロットの形状が肘が曲がっているように見えることから、エルボー法と呼ばれています。ただ、現実的には問題の結果図のような綺麗にある点でグラフが落ち込むようなエルボー図が得られることはなかなかありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 次のコードを実行することにより、**エルボー図の概略** を掴みましょう。また `KMeans`  クラスのクラスター数の幅を広げ、**エルボー法に変化があるか** 確認してみましょう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# サンプルデータの生成\n",
    "X,Y = make_blobs(n_samples=150, n_features=2, centers=3, cluster_std=0.5, shuffle=True, random_state=0)     \n",
    "\n",
    "distortions = []\n",
    "for i  in range(1,11):                # クラスター数1~10を一気に計算 \n",
    "    km = KMeans(n_clusters=i,\n",
    "                init=\"k-means++\",     # k-means++法によりクラスタ中心を選択\n",
    "                n_init=10,\n",
    "                max_iter=300,\n",
    "                random_state=0)\n",
    "    km.fit(X)                         # クラスタリングのを実行\n",
    "    distortions.append(km.inertia_)   # km.fitするとkm.inertia_が得られる\n",
    "    \n",
    "# グラフのプロット\n",
    "plt.plot(range(1,11),distortions,marker=\"o\")\n",
    "plt.xticks(np.arange(1, 11, 1))\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Distortion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- エルボー図においては、SSEの値が一度サチる(飽和する)と改善することはほとんどありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# サンプルデータの生成\n",
    "X,Y = make_blobs(n_samples=150, n_features=2, centers=3, cluster_std=0.5, shuffle=True, random_state=0)     \n",
    "\n",
    "distortions = []\n",
    "for i  in range(1,11):                # クラスター数1~10を一気に計算 \n",
    "    km = KMeans(n_clusters=i,\n",
    "                init=\"k-means++\",     # k-means++法によりクラスタ中心を選択\n",
    "                n_init=10,\n",
    "                max_iter=300,\n",
    "                random_state=0)\n",
    "    km.fit(X)                         # クラスタリングのを実行\n",
    "    distortions.append(km.inertia_)   # km.fitするとkm.inertia_が得られる\n",
    "    \n",
    "# グラフのプロット\n",
    "plt.plot(range(1,11),distortions,marker=\"o\")\n",
    "plt.xticks(np.arange(1, 11, 1))\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Distortion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name",
    "sectionId": "Sk6mOA7-e-G"
   },
   "source": [
    "## 2.3 DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "courseId": 5030,
    "exerciseId": "r1ZM53IjUgz",
    "id": "code_session_name",
    "important": true,
    "isDL": false,
    "timeoutSecs": 5
   },
   "source": [
    "### 2.3.1 DBSCANのアルゴリズム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "今まで見てきた **k-means法** は、**クラスター中心に出来るだけデータが集まる** ようにクラスタリングしていました。そのため、必然的に **クラスターは円形(球状)に近い形** を取ります。 **クラスターの大きさ・形に偏りがないときは効果を発揮します** が、 **クラスターの大きさ・形に偏りがあるデータの場合は良いクラスタリングができない** 傾向にあります。<br>\n",
    " \n",
    " 　**k-means法** に対して、別の非階層クラスタリングのアルゴリズムに **<font color=#AA0000>「DBSCAN」</font>** があります。**<font color=#AA0000>「DBSCAN」</font>** のアルゴリズムは、 **クラスターを高密度(データが凝集している)の場所を低密度の場所から分離して** 捉えます。**クラスターサイズ・形に偏りがある際に真価を発揮します。**\n",
    "  \n",
    "　**<font color=#AA0000>「DBSCAN」</font>** では、**2つ**のパラメータを定義します。 `min_samples`と`eps`です。 **<font color=#AA0000>「DBSCAN」</font>** のアルゴリズムでは、次の **3種類** にデータ点を分類します\n",
    "\n",
    " 1.あるデータの半径 `eps` 内に `min_sample` 数だけのデータがある場合、そのデータ点は **コア点** とみなします。<br>\n",
    "\n",
    " 2.また、**コア点** ではないが、**コア点から半径 `eps` 内に入っているデータ**は、**ボーダー点**とみなします。 <br>\n",
    "\n",
    " 3.どちらにも満たさないデータ点は、**ノイズ点** と見まします。\n",
    "\n",
    "**コア点の集まり** から**クラスターを形成** します。**ボーダー点** は、**最も近いコア点の属するクラスターに割り振られます。** このように **<font color=#AA0000>「DBSCAN」</font>** のアルゴリズムでは、全データを3つのデータに分類することにより、 **偏ったデータや、平均的ではないクラスターも分類できるようになり、ノイズを正しく除去することもできます**。\n",
    " \n",
    "　**<font color=#AA0000>「DBSCAN」</font>**  は、`sklearn.cluster`の`DBSCAN`クラスを利用することができます。主なパラメータとして、`eps`、`min_sample`、 `metric`により距離計算法を指定します。\n",
    "```python\n",
    "from sklearn.cluster import DBSCAN\n",
    "db = DBSCAN(eps=0.2,\n",
    "            min_samples=5,\n",
    "            metric=\"euclidean\")\n",
    "Y_db = db.fit_predict(X)\n",
    "```\n",
    "問題で、**k-means法とDBSCANの分類結果を比べて見ましょう。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 次のコードを完成することにより、**k-means法とDBSCANの分類結果の相違を確認**してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# 月型のデータを生成\n",
    "X, Y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "\n",
    "# グラフと2つの軸を定義 左はk-means法用、右はDBSCAN用\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,3))\n",
    "\n",
    "#k-means法\n",
    "km = KMeans(n_clusters=2, random_state=0)\n",
    "Y_km = km.fit_predict(X)\n",
    "\n",
    "ax1.scatter(X[Y_km==0, 0], X[Y_km==0, 1], c=\"lightblue\", marker=\"o\", s=40, label=\"cluster 1\")\n",
    "ax1.scatter(X[Y_km==1, 0], X[Y_km==1, 1], c=\"red\", marker=\"s\", s=40, label=\"cluster 2\")\n",
    "ax1.set_title(\"K-means clustering\")\n",
    "\n",
    "# DBSCANでクラスタリング # コードを完成してください\n",
    "db = \n",
    "Y_db = \n",
    "\n",
    "ax2.scatter(X[Y_db==0, 0], X[Y_db==0, 1], c=\"lightblue\", marker=\"o\", s=40, label=\"cluster 1\")\n",
    "ax2.scatter(X[Y_db==1, 0], X[Y_db==1, 1], c=\"red\", marker=\"s\", s=40, label=\"cluster 2\")\n",
    "ax2.set_title(\"DBSCAN clustering\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- k-means法は、今回のような複雑な形状をもったデータに弱い反面、DBSCANは、任意の形状をクラスタリングすることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# 月型のデータを生成\n",
    "X, Y = make_moons(n_samples=200, noise=0.05, random_state=0)\n",
    "\n",
    "# グラフと2つの軸を定義 左はk-means法用、右はDBSCAN用\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,3))\n",
    "\n",
    "#k-means法\n",
    "km = KMeans(n_clusters=2, random_state=0)\n",
    "Y_km = km.fit_predict(X)\n",
    "\n",
    "ax1.scatter(X[Y_km==0, 0], X[Y_km==0, 1], c=\"lightblue\", marker=\"o\", s=40, label=\"cluster 1\")\n",
    "ax1.scatter(X[Y_km==1, 0], X[Y_km==1, 1], c=\"red\", marker=\"s\", s=40, label=\"cluster 2\")\n",
    "ax1.set_title(\"K-means clustering\")\n",
    "\n",
    "# DBSCANでクラスタリング\n",
    "db = DBSCAN(eps=0.2, min_samples=5, metric=\"euclidean\")\n",
    "Y_db = db.fit_predict(X)\n",
    "\n",
    "ax2.scatter(X[Y_db==0, 0], X[Y_db==0, 1], c=\"lightblue\", marker=\"o\", s=40, label=\"cluster 1\")\n",
    "ax2.scatter(X[Y_db==1, 0], X[Y_db==1, 1], c=\"red\", marker=\"s\", s=40, label=\"cluster 2\")\n",
    "ax2.set_title(\"DBSCAN clustering\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chapter_exam"
   },
   "source": [
    "## 2.4 添削問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    " 円状のデータのクラスタリングにおいて、k-means法とDBSCANによる結果の違いを見て見ましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- sklearn.datasetsモジュールの「make_circles」関数を利用し、円状のデータを生成させた後、それらをk-means法とDBSCANを用いてクラスタリング、可視化しましょう。なお、結果図は、左にk-means法によるクラスタリング結果、右にDBSCANによるクラスタリング結果が表示されるようにしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_circles\n",
    " \n",
    "# 円状のデータを生成\n",
    "\n",
    "# figureオブジェクトの生成、並びに2軸の定義\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "# k-meansのインスタンス化\n",
    "\n",
    "\n",
    "# DBSCANのインスタンス化\n",
    "\n",
    "\n",
    "# 左にk-means法によるクラスタリングの結果を表示\n",
    "\n",
    "\n",
    "# 右にDBSCANによるクラスタリングの結果を表示\n",
    "\n",
    "# 可視化\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 円状のデータは、X, y = make_circles(n_samples=150, random_state=4, noise=0.05, factor=0.5)と書くことで、計算することができます。\n",
    "- DBSCANは、パラメータeps, min_samplesの値によってクラスタリングの結果が著しく変わるため、調整が必要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_circles\n",
    " \n",
    "# 円状のデータを生成\n",
    "X, y = make_circles(n_samples=150, random_state=4, noise=0.05, factor=0.5)\n",
    "# figureオブジェクトの生成、並びに2軸の定義\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "# k-meansのインスタンス化\n",
    "km = KMeans(n_clusters=2, random_state=0)\n",
    "Y_km = km.fit_predict(X)\n",
    "\n",
    "# DBSCANのインスタンス化\n",
    "db = DBSCAN(eps=0.3, min_samples=7, metric=\"euclidean\")\n",
    "Y_db = db.fit_predict(X)\n",
    "\n",
    "# 左にk-means法によるクラスタリングの結果を表示\n",
    "ax1.scatter(X[Y_km==0, 0], X[Y_km==0, 1])\n",
    "ax1.scatter(X[Y_km==1, 0], X[Y_km==1, 1])\n",
    "ax1.set_title(\"k-means\")\n",
    "\n",
    "# 右にDBSCANによるクラスタリングの結果を表示\n",
    "ax2.scatter(X[Y_db==0, 0], X[Y_db==0, 1])\n",
    "ax2.scatter(X[Y_db==1, 0], X[Y_db==1, 1])\n",
    "ax2.set_title(\"DBSCAN\")\n",
    "\n",
    "# 可視化\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解説"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "commentary"
   },
   "source": [
    "　k-means法は、全てのクラスターを同じサイズに統一しようとする性質があり結果図のように、円状のデータが半分に分かれていることがわかります。つまりこのようなデータには、不向きです。反対に、DBSCANは不均一なデータにも対処できるため、結果図のように円状のデータも綺麗に分割できることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}