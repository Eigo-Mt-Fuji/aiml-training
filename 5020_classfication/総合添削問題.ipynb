{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final_exam",
    "timeout": 300
   },
   "source": [
    "# 総合添削問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "教師あり学習（分類）の総合添削問題はこれまでの手法の特性とハイパーパラメーターのチューニングの重要性、そしてハイパーパラメーターのサーチ方法を理解しているかを問う問題となっています。  \n",
    "使用するデータセットは手書きの数字の画像であり、判別しにくい数字もあることからパラメーターサーチや手法選択がより重要になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 手書きの数字の認識・分類をするための学習器をより高い精度で作成したいと思います。\n",
    "- 与えられるデータに対して手法を選び、ハイパーパラメーターを調整して学習能力の高い学習器を作ってください。\n",
    "- また、一番評価の高い手法の名前と、調整したパラメーターとその値を出力してください。\n",
    "----\n",
    "- 採点基準は問題文の条件を満たしている状態で、以下の事項を考慮して総合的に採点いたします。\n",
    "    - 評価値の高さ\n",
    "    - パラメーターの調整方法\n",
    "    - プログラムの実行時間\n",
    "$- また、プログラムの実行時間は3分以内とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "index",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: 0.9667783570083582\n",
      "SVC: 0.5937365791995064\n",
      "LinearSVC: 0.9622544112644402\n",
      "DecisionTreeClassifier: 0.850343420582349\n",
      "RandomForestClassifier: 0.9569939429176506\n",
      "KNeighborsClassifier: 0.9942462891080195\n",
      "LogisticRegression: 0.9667783570083582\n",
      "学習モデル: KNeighborsClassifier, パラメーター: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}, F1 :  0.9942\n",
      "CPU times: user 8.99 s, sys: 231 ms, total: 9.23 s\n",
      "Wall time: 8.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 必要なモジュールがあれば追記してください\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "data = load_digits()\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    data.data, data.target, random_state=42)\n",
    "\n",
    "# 以下にコードを記述してください\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "## LogisticRegression\n",
    "model1 = LogisticRegression(random_state=42)\n",
    "model1.fit(train_X, train_y)\n",
    "\n",
    "## SVC\n",
    "model2 = SVC(random_state=42)\n",
    "model2.fit(train_X, train_y)\n",
    "\n",
    "## LinearSVC\n",
    "model3 = LinearSVC(random_state=42, max_iter=300000)\n",
    "model3.fit(train_X, train_y)\n",
    "\n",
    "## DecisionTreeClassifier\n",
    "model4 = DecisionTreeClassifier()\n",
    "model4.fit(train_X, train_y)\n",
    "\n",
    "## RandomForestClassifier\n",
    "model5 = RandomForestClassifier()\n",
    "model5.fit(train_X, train_y)\n",
    "\n",
    "## KNeighborsClassifier\n",
    "model6 = KNeighborsClassifier(n_neighbors= 5)\n",
    "model6.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "def display_the_best(models, test_X, test_y):\n",
    "    scores = []\n",
    "   \n",
    "    for m in models:\n",
    "        # get score\n",
    "        score = m.score(test_X, test_y)\n",
    "        \n",
    "        # get f1 score\n",
    "        pred_y = m.predict(test_X)\n",
    "        true_y = test_y\n",
    "#        print(pred_y)\n",
    "        missing_datas = []\n",
    "        for i in range(len(pred_y)):\n",
    "            if pred_y[i] != true_y[i]:\n",
    "                missing_datas.extend([{\"index\": i, \"true_y\": true_y[i], \"pred_y\": pred_y[i]}])\n",
    "        f1 = f1_score(true_y, pred_y, average='macro') \n",
    "        print(\"%s: %s\" % (m.__class__.__name__, f1))\n",
    "        scores.extend([ { \"model_name\" : m.__class__.__name__, \"model_parameters\": m.get_params(deep=False), \"score\" : score, \"f1_score\": f1, \"missing_datas\": missing_datas} ])\n",
    "\n",
    "    df = pd.DataFrame(scores, columns=[\"model_name\", \"model_parameters\", \"missing_datas\", \"score\", \"f1_score\"]) \n",
    "    best_model = df.loc[df['f1_score'].idxmax()]\n",
    "#    print(best_score[\"missing_datas\"])\n",
    "    print( \"学習モデル: %s, パラメーター: %s, F1 :  %.4f\"  %(best_model[\"model_name\"], best_model[\"model_parameters\"], best_model[\"f1_score\"]))\n",
    "\n",
    "# 最も成績のいいスコアを出力してください。\n",
    "display_the_best([model1, model2, model3, model4, model5, model6, model7], test_X, test_y)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- プログラムの実行時間を計測するにはプログラムの先頭に`%%time`と記述してください。\n",
    "    - jupyter notebook上でのみ実行できるおまじないです。Pythonのプログラムでは実行できないので注意してください。\n",
    "- モデルの手法の名前をプログラムで取得するには`model_name = model.__class__.__name__`とします。\n",
    "- グリッドサーチ、ランダムサーチの結果得られるパラメーターセットを取得するには`best_params = clf.best_params_`とします。\n",
    "- 最高評価を得たモデルが複数ある場合、そのうちの一つだけ出力すれば良いです。\n",
    "- 採点時、モデルの評価にはF値という値を用います。\n",
    "    - F値はprecision(精度)とrecall(再現率)という二つの評価値の調和平均です。  \n",
    "    $$\n",
    "    \\begin{align}\n",
    "    & \\frac{2 ( precision \\times recall )}{precision + recall}\n",
    "    \\end{align}\n",
    "    $$\n",
    "    - プログラムを作る際には`model.score(test_X, test_y)`で構いませんが、  \n",
    "    自身で評価を確認したい場合はモデルに教師データを学習させたのち以下のようにします。\n",
    "    ```python\n",
    "    from sklearn.metrics import f1_score\n",
    "    # モデルにデータを予測させる\n",
    "    pred_y = clf.predict(testX)\n",
    "    \n",
    "    # モデルのF値を計算する\n",
    "    score = f1_score(test_y, pred_y, average=\"micro\")\n",
    "    ```\n",
    "- 今回のデータセットに関する情報は[UCI Machine Learning Repository(英語版サイト)](http://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits)を参照してください。\n",
    "- 講座でいくつかのパラメーターを手法ごとに紹介しましたが、他にも調整可能なパラメーターが存在します。  \n",
    "[scikit-learnのドキュメント(英語版サイト)](http://scikit-learn.org/stable/modules/classes.html)を参照してください。  \n",
    "また、パラメーターに関してわからないことがあればチューターまでご質問ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  解答例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "commentary"
   },
   "source": [
    "添削課題の提出は以下のアドレスから提出いただきますようお願いします。<br>\n",
    "\b\n",
    "https://goo.gl/forms/fW7CAspZMwHuWuqk2<br><br>\n",
    "以下のアドレスからアンケートにご協力頂きたく存じます。<br>\n",
    "ご回答のほど、よろしくお願いいたします。\n",
    "\n",
    "https://goo.gl/forms/WHjJQYeodIndRvyz2"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
