{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chapter_name"
   },
   "source": [
    "#  レコメンドシステム入門chapter1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "table"
   },
   "source": [
    "\n",
    "- **[1.1 レコメンドシステムとは](#1.1-レコメンドシステムとは)**\n",
    "    - **[1.1.1 概要](#1.1.1-概要)**\n",
    "    - **[1.1.2 協調フィルタリング](#1.1.2-協調フィルタリング)**\n",
    "<br><br>\n",
    "- **[1.2 コンテンツベースフィルタリング](#1.2-コンテンツベースフィルタリング)**\n",
    "    - **[1.2.1 コンテンツベースフィルタリングとは](#1.2.1-コンテンツベースフィルタリングとは)**\n",
    "    - **[1.2.2 アイテムの特徴ベクトル抽出](#1.2.2-アイテムの特徴ベクトル抽出)**\n",
    "    - **[1.2.3 類似度の判定](#1.2.3-類似度の判定)**\n",
    "    - **[1.2.4 レコメンドの実行](#1.2.3-レコメンドの実行)**\n",
    "<br><br>\n",
    "- **[添削問題 コンテンツベースフィルタリングの実装課題](#添削問題-コンテンツベースフィルタリングの実装課題)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name"
   },
   "source": [
    "## 1.1 レコメンドシステムとは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quiz_session_name"
   },
   "source": [
    "### 1.1.1 概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "レコメンデーションシステムとは、商品を推薦するシステムのことです。   \n",
    "レコメンデーションの有名な例として、アマゾンなどネットショッピングのレコメンドシステムがあります。   \n",
    "商品を買ったとき「この商品を買った人はこちらの商品も買っています。」などの広告が下に表示されると思います。   \n",
    "これがレコメンドシステムになります。   \n",
    "\n",
    "現在は非常に多くのデータに囲まれて生活しています。   \n",
    "Googleなどの検索サービスや、商品の人気順などの並び替えもレコメンドです。   \n",
    "膨大なデータからレコメンドすることによって様々なサービスが成り立っています。\n",
    "\n",
    "ここからはレコメンドの種類について考えていきます。\n",
    "\n",
    "レコメンドシステムは用いる情報の種類によって分類することができます。大きく分けると、アイテムベース/ユーザーベースです。例えば店頭の商品の情報から似たようなものをセットで販売すると言う時は、アイテムベースのレコメンドになります。また、購入者の履歴や同じ購入パターンの人を分析して、ある商品を買った人に商品を勧めると言う時は、ユーザーベースのレコメンドになります。レコメンドをする際にベースとなる情報の違いにより、実装方法も変わってきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 次のうち、ユーザーベースのレコメンデーションはどれでしょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. ECサイトで閲覧しているアイテムと似たアイテムを勧める\n",
    "1. テニスラケットとテニスボールが良く同時に売れるのでセットで売り出す\n",
    "1. Aさんの欲しいモノリストに筋トレグッズが多かったので、プロテインを勧める\n",
    "1. 上記のすべて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- ユーザーベースではユーザーの情報を元にレコメンドされています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "Aさんの欲しいモノリストに筋トレグッズが多かったので、プロテインを勧める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "code_session_name"
   },
   "source": [
    "### 1.1.2 主流のシステム -協調フィルタリングとは-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "Amazonでは他のユーザーの購入パターンを用いて、商品をオススメしています。他ユーザーの行動パターンやアイテムの類似性を対象のユーザーと比較するレコメンドシステムを協調フィルタリングと言います。協調フィルタリングでは、似ているユーザー/アイテムを購買履歴やレーティングなどから導き、ユーザー同士またはユーザーとアイテムを繋げます。例えば、漫画の趣味があう友人にオススメの漫画を教えてもらうのは協調フィルタリングに分類されます。良く使われるレコメンドシステムであり、チャプター2で実装を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 次のうち、協調フィルタリングはどれでしょう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. Amazonの「この商品を買った人はこんな商品も買ってます」\n",
    "1. Bさんがテクノロジー系の本を良く買っているので、Bさんに人工知能の本を勧める\n",
    "1. ランキングで上位のものをオススメの映画として勧める。\n",
    "1. 上記のすべて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 協調フィルタリングでは複数のユーザーが複数のアイテムにアクションを起こすことでユーザーを通したアイテムの共通点、アイテムを通したユーザーの共通点を導き出す手法です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "Amazonの「この商品を買った人はこんな商品も買ってます」"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "section_name"
   },
   "source": [
    "## 1.2 コンテンツベースフィルタリング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quiz_session_name"
   },
   "source": [
    "### 1.2.1 コンテンツベースフィルタリングとは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "あるユーザーのプロフィールや過去の購買履歴から、そのユーザーの個人的な嗜好を見つけてコンテンツを勧める手法を、コンテンツベースフィルタリングと言います。食べログのように食べたい場所、値段、食事の種類などを入力してオススメするのもコンテンツベースフィルタリングに分類されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- 次のうちコンテンツベースフィルタリングはどれでしょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "choices"
   },
   "source": [
    "1. DVDのレンタルショップで映画をジャンルに分けて配置している\n",
    "1. ECサイトで閲覧しているアイテムと似た属性情報を持つアイテムを勧める\n",
    "1. Cさんの登録情報からオススメの本を教える\n",
    "1. 上記のすべて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- コンテンツベースでは他ユーザーの情報を使用しません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answer"
   },
   "source": [
    "上記のすべて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "code_session_name"
   },
   "source": [
    "### 1.2.2 アイテムの特徴ベクトル抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "\n",
    "それではここからは実際にコンテンツベースフィルタリングを実装してみましょう。   \n",
    "コンテンツベースフィルタリングの具体的な実装方法は以下のようになります。   \n",
    "1. アイテムから単語を抜き出し、その単語がアイテムの中でどれだけ大切かを求め、これを並べて特徴ベクトルをつくる。\n",
    "2. 先ほど求めた特徴ベクトルを他のアイテムの特徴ベクトルと比較して類似度を求める。\n",
    "3. 類似度の高いデータをレコメンドする。\n",
    "\n",
    "まずはアイテムの名前や説明文などから特徴ベクトルを抽出します。TF は Term Frequency、単語の出現頻度。IDF は Inverse Document Frequency、単語の希少性。単語の出現頻度と希少性をふたつ掛け合わせた値がTF-IDFです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に解析を始める前に"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFとIDFの値はそれぞれ次のように計算できます。   \n",
    "<br>\n",
    "$ \\large TF = \\frac{対象の文章中に含まれる調べたい単語の数}{対象の文章中に含まれる全ての単語の数}$   \n",
    "\n",
    "$ \\large IDF = log_{10}\\frac{すべての文章の数}{その単語が出現する文章の数} $\n",
    "\n",
    "実際にTFとIDFを計算しましょう。\n",
    "\n",
    "```python\n",
    "def tf(terms):\n",
    "    terms_unique = set(terms)\n",
    "    tf_values = [terms.count(term) for term in terms_unique]\n",
    "    tf_list = list(map(lambda x: x/sum(tf_values), tf_values))\n",
    "    return np.array(tf_list)\n",
    "\n",
    "\n",
    "def idf(terms, documents):\n",
    "    import math\n",
    "    terms = set(terms)\n",
    "    idf_list = [math.log10((len(documents)+1)/(sum([bool(term in document) for document in documents])+1)) for term in terms]\n",
    "    return np.array(idf_list)\n",
    "   ```\n",
    "   \n",
    "terms には単語のリストを代入し、documentにはすべての文章の単語リストを加えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "textは肉フェスに関する文章を品詞分解し、名詞のみをまとめてリストにしたものです。   \n",
    "TF-IDFで文章から文字の特徴ベクトルを抜き出してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "text = [\n",
    "    [ 'ハウス', 'ワサビ', '雪', 'フェス', '熟成', '牛', '三昧', '産', '県', 'ステーキ', 'ワサビ','ごはん','牛', '夜', '塩', 'あづま', '肉','ごはん', '新潟']\n",
    "    ,['引き上げ', 'マリネ', 'グリル', '使用','牛' '様', 'スパイス', '香辛料', 'カット', '旨み', '応え', '抜群', 'ステーキ', '厚め', '肉']\n",
    "    ,['ワンダーランド', 'イベント', '好き', '紹介', 'フェス', '現在', '料理', '出店', 'こちら', '注目', '各地', '店舗', '全国', '肉', '東京']\n",
    "        ]\n",
    "# 以下の空欄を埋めてtf関数を完成させてください。\n",
    "def tf(terms):\n",
    "    terms_unique = \n",
    "    tf_values = \n",
    "    tf_list =\n",
    "    return \n",
    "\n",
    "# 以下の空欄を埋めてidf関数を完成させてください。\n",
    "def idf(terms, documents):\n",
    "    import math\n",
    "    terms = \n",
    "    idf_list =\n",
    "    return\n",
    "\n",
    "# 以下の空欄を埋めてtfidfを求めてください。\n",
    "tf = \n",
    "idf = \n",
    "tfidf = tf*idf\n",
    "for n,word in enumerate(set(text[0])):\n",
    "    data.append([word, tfidf[n]])\n",
    "data = sorted(data, key=lambda x: -x[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "・tf×idfを計算するためにtfとidfはndarrayの形にしましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "text = [\n",
    "    [ 'ハウス', 'ワサビ', '雪', 'フェス', '熟成', '牛', '三昧', '産', '県', 'ステーキ', 'ワサビ','ごはん','牛', '夜', '塩', 'あづま', '肉','ごはん', '新潟']\n",
    "    ,['引き上げ', 'マリネ', 'グリル', '使用','牛' '様', 'スパイス', '香辛料', 'カット', '旨み', '応え', '抜群', 'ステーキ', '厚め', '肉']\n",
    "    ,['ワンダーランド', 'イベント', '好き', '紹介', 'フェス', '現在', '料理', '出店', 'こちら', '注目', '各地', '店舗', '全国', '肉', '東京']\n",
    "        ]\n",
    "\n",
    "# 以下の空欄を埋めてtf関数を完成させてください。\n",
    "def tf(terms):\n",
    "    terms_unique = set(terms)\n",
    "    tf_values = [terms.count(term) for term in terms_unique]\n",
    "    tf_list = list(map(lambda x: x/sum(tf_values), tf_values))\n",
    "    return np.array(tf_list)\n",
    "\n",
    "# 以下の空欄を埋めてidf関数を完成させてください。\n",
    "def idf(terms, documents):\n",
    "    import math\n",
    "    terms = set(terms)\n",
    "    idf_list = [math.log10((len(documents)+1)/(sum([bool(term in document) for document in documents])+1)) for term in terms]\n",
    "    return np.array(idf_list)\n",
    "\n",
    "# 以下の空欄を埋めてtfidfを求めてください。\n",
    "data = []\n",
    "tf = tf(text[0])\n",
    "idf = idf(text[0], text)\n",
    "tfidf = tf*idf\n",
    "for n,word in enumerate(set(text[0])):\n",
    "    data.append([word, tfidf[n]])\n",
    "data = sorted(data, key=lambda x: -x[1])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "code_session_name"
   },
   "source": [
    "### 1.2.3 類似度の判定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "今回はコサイン類似度を使って、特徴ベクトルの類似度を判定します。   \n",
    "コサイン類似度とは、文書同士を比較する際によく用いられる計算手法です。   \n",
    "三角関数の普通のコサインの通り、1に近ければ類似しており、0に近ければ似ていないことになります。ベクトル間の類似度を求める時に良く使われています。\n",
    "\n",
    "```python\n",
    "def similarity(vec1,vec2):\n",
    "    #ベクトル同士の内積を求めましょう。\n",
    "    vec1_dict = {key: value for key, value in vec1}\n",
    "    ab = 0  \n",
    "    for key2, value2 in vec2:\n",
    "        value1 = vec1_dict.get(key2)\n",
    "        if value1:\n",
    "            ab += value1 * value2\n",
    "            \n",
    "    a = math.sqrt(sum([v ** 2 for k, v in vec1]))\n",
    "    b = math.sqrt(sum([v ** 2 for k, v in vec2]))\n",
    "    return ab / (a * b)\n",
    "```\n",
    "詳しい実装はchapter2でやります。chapter1ではこれをコピーして使ってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "- コサイン類似度を用いて異なる二つの特徴ベクトルの類似度を計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "index"
   },
   "outputs": [],
   "source": [
    "\n",
    "# データ作成\n",
    "data1 = [['Apple', 1], ['Orange', 5], ['Banana', 2], ['Kiwi', 0]]\n",
    "data2 = [['Apple', 1], ['Orange', 0], ['Banana', 2], ['Kiwi', 3]]\n",
    "\n",
    "# コサイン類似度の処理\n",
    "\n",
    "\n",
    "# 出力\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- 上のsimilarityでは類似度の値が返されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "data1 = [['Apple', 1], ['Orange', 5], ['Banana', 2], ['Kiwi', 0]]\n",
    "data2 = [['Apple', 1], ['Orange', 0], ['Banana', 2], ['Kiwi', 3]]\n",
    "\n",
    "def similarity(vec1,vec2):\n",
    "    #ベクトル同士の内積を求めましょう。\n",
    "    vec1_dict = {key: value for key, value in vec1}\n",
    "    ab = 0  \n",
    "    for key2, value2 in vec2:\n",
    "        value1 = vec1_dict.get(key2)\n",
    "        if value1:\n",
    "            ab += value1 * value2\n",
    "\n",
    "    a = math.sqrt(sum([v ** 2 for k, v in vec1]))\n",
    "    b = math.sqrt(sum([v ** 2 for k, v in vec2]))\n",
    "    return ab / (a * b)\n",
    "\n",
    "print(similarity(data1,data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "code_session_name"
   },
   "source": [
    "### 1.2.4 レコメンドの実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "ここまで学習したものを利用して実際にレコメンドしていきます。   \n",
    "先ほどのTF-IDFによる特徴ベクトルとコサイン類似度を使って、複数の商品の中から対象者に適したものを選び出します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "\n",
    "dataは映画の題名とその映画の持っている性質のリストです。   \n",
    "このリストを使って、コンテンツベースフィルタリングを利用し、takeshiの好みに合う映画をレコメンドしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "index"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# takeshiの好みデータ\n",
    "takeshi = [['Love', 1], ['Fun', 2], ['Horror', 1], ['Life', 0]]\n",
    "\n",
    "# 映画の評価\n",
    "data = [\n",
    "    ['frozen', [['Love', 2], ['Fun', 3], ['Horror', 1], ['Life', 0]]],\n",
    "    ['nana', [['Love', 2], ['Fun', 2], ['Horror', 0], ['Life', 1]]],\n",
    "    ['friends', [['Love', 1], ['Fun', 3], ['Horror', 0], ['Life', 2]]],\n",
    "    ['ring', [['Love', 0], ['Fun', 0], ['Horror', 3], ['Life', 1]]],\n",
    "    ['juon', [['Love', 0], ['Fun', 0], ['Horror', 4], ['Life', 0]]],\n",
    "    ['titanic', [['Love', 3], ['Fun', 1], ['Horror', 0], ['Life', 1]]],\n",
    "    ['message', [['Love', 2], ['Fun', 0], ['Horror', 1], ['Life', 2]]],\n",
    "    ['gintama', [['Love', 0], ['Fun', 3], ['Horror', 0], ['Life', 2]]]\n",
    "]\n",
    "\n",
    "\n",
    "def similarity(vec1,vec2):\n",
    "    # ベクトル同士の内積を求めましょう。\n",
    "    vec1_dict = {key: value for key, value in vec1}\n",
    "    ab = 0  \n",
    "    for key2, value2 in vec2:\n",
    "        value1 = vec1_dict.get(key2)\n",
    "        if value1:\n",
    "            ab += value1 * value2\n",
    "\n",
    "    # 各ベクトルの大きさを求めましょう。\n",
    "    a = math.sqrt(sum([v ** 2 for k, v in vec1]))\n",
    "    b = math.sqrt(sum([v ** 2 for k, v in vec2]))\n",
    "    return ab / (a * b)\n",
    "\n",
    "# 類似度を計算して、最も類似度の高いものをレコメンドしてください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- それぞれの映画の評価をfor文を使ってtakeshiとの類似度を調べます。\n",
    "- オススメ順に並び変えるために [] で囲んでリスト化します。\n",
    "- 出力形式は[[題名,類似度],[],...]としましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "answer"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# takeshiの好みデータ\n",
    "takeshi = [['Love', 1], ['Fun', 2], ['Horror', 1], ['Life', 0]]\n",
    "\n",
    "# 映画の評価\n",
    "data = [\n",
    "    ['frozen', [['Love', 2], ['Fun', 3], ['Horror', 1], ['Life', 0]]],\n",
    "    ['nana', [['Love', 2], ['Fun', 2], ['Horror', 0], ['Life', 1]]],\n",
    "    ['friends', [['Love', 1], ['Fun', 3], ['Horror', 0], ['Life', 2]]],\n",
    "    ['ring', [['Love', 0], ['Fun', 0], ['Horror', 3], ['Life', 1]]],\n",
    "    ['juon', [['Love', 0], ['Fun', 0], ['Horror', 4], ['Life', 0]]],\n",
    "    ['titanic', [['Love', 3], ['Fun', 1], ['Horror', 0], ['Life', 1]]],\n",
    "    ['message', [['Love', 2], ['Fun', 0], ['Horror', 1], ['Life', 2]]],\n",
    "    ['gintama', [['Love', 0], ['Fun', 3], ['Horror', 0], ['Life', 2]]]\n",
    "]\n",
    "\n",
    "\n",
    "def similarity(vec1,vec2):\n",
    "    # ベクトル同士の内積を求めましょう。\n",
    "    vec1_dict = {key: value for key, value in vec1}\n",
    "    ab = 0  \n",
    "    for key2, value2 in vec2:\n",
    "        value1 = vec1_dict.get(key2)\n",
    "        if value1:\n",
    "            ab += value1 * value2\n",
    "\n",
    "    # 各ベクトルの大きさを求めましょう。\n",
    "    a = math.sqrt(sum([v ** 2 for k, v in vec1]))\n",
    "    b = math.sqrt(sum([v ** 2 for k, v in vec2]))\n",
    "    return ab / (a * b)\n",
    "\n",
    "# 類似度を計算して、最も類似度の高いものをレコメンドしてください。\n",
    "\n",
    "score = []\n",
    "for n,movie in enumerate(data):\n",
    "    score.append([movie[0],similarity(takeshi,movie[1])])\n",
    "    \n",
    "score = sorted(score, key=lambda x:-x[1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chapter_exam"
   },
   "source": [
    "## 添削問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "description"
   },
   "source": [
    "コンテンツベースフィルタリング最後の問題です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "question"
   },
   "source": [
    "text[0]はAidemyの広告文、text[1:4]は他社の広告文です。   \n",
    "    これらをコンテンツベースフィルタリングを利用して、Aidemyの広告文と最も類似度の高い説明文をレコメンドしてください。\n",
    "- Aidemyの説明文に対して、他社のサービスの説明文の類似度を求めてください。\n",
    "- text_aidemyと最も類似度の高い説明文のインデックスをレコメンドしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "text = np.array([['８', '週間', '集中', '特訓', '未来', '力', '身', 'Aidemy', '人工', '知能', 'プロフェッショナル', 'ため', 'オンラインゼミサービス', '一人ひとり', '個別', '指導', 'スペシャリスト', '共同', '開発', 'オリジナル', '教材', '充実', '解析', '環境', 'あなた', '学習', 'サポート', 'Aidemy', '未来', '力', '身']\n",
    "        ,['人工', '知能', '機械', '学習', 'ディープラーニング・データサイエンス', '特', '化', 'マンツーマンオンラインスクール', 'プログラミング', '言語', 'Python', '機械', '学習', 'ディープラーニング', 'データ', 'サイエンス', '目標', 'あなた', '世界', 'ひとつ', 'オーダーメイドテキスト', '提供']\n",
    "        ,['みんな', 'AI', '講座', 'ゼロ', 'Python', '人工', '知能', '機械', '学習', '初心者', '向け', '人工', '知能', '機械', '学習', 'コース', 'プログラミング', '言語', 'Python', '機械', '学習', 'プログラミング', '基礎', '必要', '数学', '勉強', '文字', '認識', '株価', '分析']\n",
    "        ,['人工', '知能', '本気', '仕事', '方', '向け', '日本', 'AI', '仕事', '紹介', 'スクール', 'AI', '人工', '知能', '活用', '必要', '統計', '知識', 'プログラミング', 'Python', '特', '化', '教育', '講座', '仕事', '紹介', '実現', 'サービス', '日本', '初', '仕事', '受講', '料', '無料']\n",
    "        ])\n",
    "\n",
    "# 以下の空欄を埋めてtf関数を完成させてください。\n",
    "def tf(terms):\n",
    "\n",
    "    \n",
    "\n",
    "# 以下の空欄を埋めてidf関数を完成させてください。\n",
    "def idf(terms, documents):\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# 以下の空欄を埋めてtfidfを求めてください。\n",
    "tfidf_text = []\n",
    "dataset = []\n",
    "for i in range(len(text)):\n",
    "    tf_data = tf(text[i])\n",
    "    idf_data = idf(text[i], text[np.arange(4) != i])\n",
    "    tfidf_data = tf_data*idf_data\n",
    "    data_bank = []\n",
    "    for n,word in enumerate(set(text[i])):\n",
    "        data_bank.append([word,tfidf_data[n]])\n",
    "        data_bank = sorted(data_bank, key= lambda x:-x[1])\n",
    "    dataset.append(data_bank)\n",
    "    \n",
    "dataset[0]\n",
    "\n",
    "def similality(vec1,vec2):\n",
    "    # ベクトル同士の内積を求めましょう。\n",
    "    vec1_dict = {key: value for key, value in vec1}\n",
    "    ab = 0  \n",
    "    for key2, value2 in vec2:\n",
    "        value1 = vec1_dict.get(key2)\n",
    "        if value1:\n",
    "            ab += value1 * value2\n",
    "\n",
    "    # 各ベクトルの大きさを求めましょう。\n",
    "    a = math.sqrt(sum([v ** 2 for k, v in vec1]))\n",
    "    b = math.sqrt(sum([v ** 2 for k, v in vec2]))\n",
    "    return ab / (a * b)\n",
    "\n",
    "# それぞれの説明文のtfidfとの類似度を求めて、最も類似度の高いものをレコメンドしてください。\n",
    "\n",
    "\n",
    "\n",
    "print('最も類似度の高い説明文のindex :', )\n",
    "print('類似度 :', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ヒント"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hint"
   },
   "source": [
    "- ここまででやったことを思い出して、tf,idfを実装しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "text = np.array([['８', '週間', '集中', '特訓', '未来', '力', '身', 'Aidemy', '人工', '知能', 'プロフェッショナル', 'ため', 'オンラインゼミサービス', '一人ひとり', '個別', '指導', 'スペシャリスト', '共同', '開発', 'オリジナル', '教材', '充実', '解析', '環境', 'あなた', '学習', 'サポート', 'Aidemy', '未来', '力', '身']\n",
    "        ,['人工', '知能', '機械', '学習', 'ディープラーニング・データサイエンス', '特', '化', 'マンツーマンオンラインスクール', 'プログラミング', '言語', 'Python', '機械', '学習', 'ディープラーニング', 'データ', 'サイエンス', '目標', 'あなた', '世界', 'ひとつ', 'オーダーメイドテキスト', '提供']\n",
    "        ,['みんな', 'AI', '講座', 'ゼロ', 'Python', '人工', '知能', '機械', '学習', '初心者', '向け', '人工', '知能', '機械', '学習', 'コース', 'プログラミング', '言語', 'Python', '機械', '学習', 'プログラミング', '基礎', '必要', '数学', '勉強', '文字', '認識', '株価', '分析']\n",
    "        ,['人工', '知能', '本気', '仕事', '方', '向け', '日本', 'AI', '仕事', '紹介', 'スクール', 'AI', '人工', '知能', '活用', '必要', '統計', '知識', 'プログラミング', 'Python', '特', '化', '教育', '講座', '仕事', '紹介', '実現', 'サービス', '日本', '初', '仕事', '受講', '料', '無料']\n",
    "        ])\n",
    "\n",
    "# 以下の空欄を埋めてtf関数を完成させてください。\n",
    "def tf(terms):\n",
    "    terms_unique = set(terms)\n",
    "    tf_values = [terms.count(term) for term in terms_unique]\n",
    "    tf_list = list(map(lambda x: x/sum(tf_values), tf_values))\n",
    "    return np.array(tf_list)\n",
    "\n",
    "# 以下の空欄を埋めてidf関数を完成させてください。\n",
    "def idf(terms, documents):\n",
    "    terms = set(terms)\n",
    "    idf_list = [math.log10((len(documents)+1)/(sum([bool(term in document) for document in documents])+1)) for term in terms]\n",
    "    return np.array(idf_list)\n",
    "\n",
    "\n",
    "# 以下の空欄を埋めてtfidfを求めてください。\n",
    "tfidf_text = []\n",
    "dataset = []\n",
    "for i in range(len(text)):\n",
    "    tf_data = tf(text[i])\n",
    "    idf_data = idf(text[i], text[np.arange(4) != i])\n",
    "    tfidf_data = tf_data*idf_data\n",
    "    data_bank = []\n",
    "    for n,word in enumerate(set(text[i])):\n",
    "        data_bank.append([word,tfidf_data[n]])\n",
    "        data_bank = sorted(data_bank, key= lambda x:-x[1])\n",
    "    dataset.append(data_bank)\n",
    "    \n",
    "dataset[0]\n",
    "\n",
    "def similality(vec1,vec2):\n",
    "    # ベクトル同士の内積を求めましょう。\n",
    "    vec1_dict = {key: value for key, value in vec1}\n",
    "    ab = 0  \n",
    "    for key2, value2 in vec2:\n",
    "        value1 = vec1_dict.get(key2)\n",
    "        if value1:\n",
    "            ab += value1 * value2\n",
    "\n",
    "    # 各ベクトルの大きさを求めましょう。\n",
    "    a = math.sqrt(sum([v ** 2 for k, v in vec1]))\n",
    "    b = math.sqrt(sum([v ** 2 for k, v in vec2]))\n",
    "    return ab / (a * b)\n",
    "\n",
    "# それぞれの説明文のtfidfとの類似度を求めて、最も類似度の高いものをレコメンドしてください。\n",
    "max_score = 0\n",
    "max_index = 0\n",
    "for i in range(1,4):\n",
    "    if max_score < similality(dataset[0],dataset[i]):\n",
    "        max_score = similality(dataset[0],dataset[i])\n",
    "        max_index = i\n",
    "\n",
    "print('最も類似度の高い説明文のindex :',max_index)\n",
    "print('類似度 :',max_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}